{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸš€ FIXED: RAG Pipeline for Test Case Generation with Gemini (JSON Mode)\n",
    "\n",
    "## âœ¨ What's New in This Fixed Version:\n",
    "\n",
    "### 1. **JSON Mode Enforcement** ðŸŽ¯\n",
    "- Uses Gemini's `response_mime_type=\"application/json\"` to guarantee valid JSON output\n",
    "- No more regex parsing or complex error handling - just clean `json.loads()`!\n",
    "\n",
    "### 2. **Improved Context Formatting** ðŸ“š\n",
    "- Clear headers and boundaries for each context document\n",
    "- Better structure helps the LLM understand source information\n",
    "\n",
    "### 3. **Robust YAML Parsing** ðŸ”§\n",
    "- Properly parses API specifications and creates meaningful chunks\n",
    "- Each endpoint becomes a separate searchable chunk\n",
    "\n",
    "### 4. **Production-Ready Architecture** ðŸ—ï¸\n",
    "- Document-based approach using real files (user stories, PRDs, API specs)\n",
    "- Scalable for the NASSCOM hackathon requirements\n",
    "\n",
    "---\n",
    "\n",
    "This notebook implements a **reliable** Retrieval-Augmented Generation (RAG) pipeline that:\n",
    "1. Loads real project documents from files\n",
    "2. Creates embeddings and builds a FAISS index for semantic search\n",
    "3. Retrieves relevant context for test requirements\n",
    "4. Generates high-quality test cases using Gemini with guaranteed JSON output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Libraries imported successfully!\n",
      "Python version: 3.13.7 (main, Aug 14 2025, 11:12:11) [Clang 17.0.0 (clang-1700.0.13.3)]\n",
      "FAISS version: 1.12.0\n",
      "âœ… Gemini API key found in environment\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import yaml\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import faiss\n",
    "from pathlib import Path\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import google.generativeai as genai\n",
    "from typing import List, Dict, Any, Tuple, Optional\n",
    "from dataclasses import dataclass, asdict\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"FAISS version: {faiss.__version__ if hasattr(faiss, '__version__') else 'Available'}\")\n",
    "\n",
    "# Check for Gemini API key\n",
    "if os.getenv('GEMINI_API_KEY'):\n",
    "    print(\"âœ… Gemini API key found in environment\")\n",
    "else:\n",
    "    print(\"âš ï¸ Warning: GEMINI_API_KEY not found in .env file\")\n",
    "    print(\"Please add your Gemini API key to the .env file\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Configure Gemini API\n",
    "\n",
    "Setting up Gemini with proper configuration for healthcare test generation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Gemini API connected successfully!\n",
      "Test response: Hello!...\n",
      "âœ… Gemini model configured for test generation\n"
     ]
    }
   ],
   "source": [
    "# Configure Gemini\n",
    "genai.configure(api_key=os.getenv('GEMINI_API_KEY'))\n",
    "\n",
    "# Initialize base Gemini model for testing\n",
    "base_model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "\n",
    "# Test Gemini connection\n",
    "try:\n",
    "    response = base_model.generate_content(\"Hello, Gemini! Respond with a brief greeting.\")\n",
    "    print(\"âœ… Gemini API connected successfully!\")\n",
    "    print(f\"Test response: {response.text[:100]}...\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error connecting to Gemini: {e}\")\n",
    "    print(\"Please check your API key in the .env file\")\n",
    "\n",
    "# Default generation config for test cases\n",
    "default_generation_config = {\n",
    "    'temperature': 0.3,  # Low temperature for consistent output\n",
    "    'top_p': 0.9,\n",
    "    'top_k': 30,\n",
    "    'max_output_tokens': 2000,\n",
    "}\n",
    "\n",
    "# Safety settings for healthcare content\n",
    "safety_settings = [\n",
    "    {\"category\": \"HARM_CATEGORY_HARASSMENT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_HATE_SPEECH\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\", \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"},\n",
    "    {\"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\", \"threshold\": \"BLOCK_NONE\"}  # Allow medical content\n",
    "]\n",
    "\n",
    "print(\"âœ… Gemini model configured for test generation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load Documents from Files (IMPROVED)\n",
    "\n",
    "Load real project documents with better parsing, especially for YAML files.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading documents from: /Users/shtlpmac036/Documents/Personal/GenAI Hack /data/documents\n",
      "Found 5 files\n",
      "\n",
      "   âœ… Loaded: user_story_registration.txt (2273 chars)\n",
      "   âœ… Loaded: bug_report_template.txt (2884 chars)\n",
      "   âœ… Loaded: api_spec_v1.yaml (API v1.0.0)\n",
      "      - Created 4 chunks (3 endpoints + info)\n",
      "   âœ… Loaded: test_plan_user_management.md (3971 chars)\n",
      "   âœ… Loaded: prd_account_management.md (2931 chars)\n",
      "\n",
      "ðŸ“Š Document Summary:\n",
      "Total document chunks loaded: 8\n",
      "\n",
      "Document types:\n",
      "  - text: 2 chunks\n",
      "  - api_info: 1 chunks\n",
      "  - api_endpoint: 3 chunks\n",
      "  - markdown: 2 chunks\n",
      "\n",
      "âœ… Documents loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Path to documents folder\n",
    "DOCUMENTS_PATH = \"/Users/shtlpmac036/Documents/Personal/GenAI Hack /data/documents\"\n",
    "\n",
    "def load_documents_from_folder_improved(folder_path):\n",
    "    \"\"\"Load all documents from a folder with improved parsing\"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    # Get all files in the documents folder\n",
    "    document_files = glob.glob(f\"{folder_path}/*\")\n",
    "    \n",
    "    print(f\"ðŸ“‚ Loading documents from: {folder_path}\")\n",
    "    print(f\"Found {len(document_files)} files\\n\")\n",
    "    \n",
    "    for file_path in document_files:\n",
    "        file_name = Path(file_path).name\n",
    "        file_extension = Path(file_path).suffix\n",
    "        \n",
    "        try:\n",
    "            if file_extension in ['.txt', '.md']:\n",
    "                # Load text and markdown files\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    content = f.read()\n",
    "                    \n",
    "                    # Create document entry\n",
    "                    documents.append({\n",
    "                        'filename': file_name,\n",
    "                        'type': 'text' if file_extension == '.txt' else 'markdown',\n",
    "                        'content': content,\n",
    "                        'metadata': {\n",
    "                            'source': file_path,\n",
    "                            'doc_type': 'user_story' if 'user_story' in file_name.lower() else \n",
    "                                       'prd' if 'prd' in file_name.lower() else\n",
    "                                       'test_plan' if 'test' in file_name.lower() else\n",
    "                                       'bug_report' if 'bug' in file_name.lower() else 'general'\n",
    "                        }\n",
    "                    })\n",
    "                    print(f\"   âœ… Loaded: {file_name} ({len(content)} chars)\")\n",
    "                    \n",
    "            elif file_extension in ['.yaml', '.yml']:\n",
    "                # IMPROVED: Load and properly parse YAML files\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    yaml_content = yaml.safe_load(f)\n",
    "                    api_info = yaml_content.get('info', {})\n",
    "                    \n",
    "                    # Add general API info as one document\n",
    "                    info_content = yaml.dump({'info': api_info}, default_flow_style=False)\n",
    "                    documents.append({\n",
    "                        'filename': file_name,\n",
    "                        'type': 'api_info',\n",
    "                        'content': info_content,\n",
    "                        'metadata': {\n",
    "                            'source': file_path,\n",
    "                            'doc_type': 'api_specification',\n",
    "                            'api_version': api_info.get('version', 'unknown'),\n",
    "                            'api_title': api_info.get('title', 'API')\n",
    "                        }\n",
    "                    })\n",
    "                    \n",
    "                    # Create a separate document for each API endpoint\n",
    "                    paths = yaml_content.get('paths', {})\n",
    "                    for path, methods in paths.items():\n",
    "                        # Convert just this endpoint's data to a string\n",
    "                        endpoint_content = f\"API Endpoint: {path}\\n\\n\"\n",
    "                        endpoint_content += yaml.dump(methods, default_flow_style=False)\n",
    "                        \n",
    "                        documents.append({\n",
    "                            'filename': file_name,\n",
    "                            'type': 'api_endpoint',\n",
    "                            'content': endpoint_content,\n",
    "                            'metadata': {\n",
    "                                'source': file_path,\n",
    "                                'doc_type': 'api_specification',\n",
    "                                'api_version': api_info.get('version', 'unknown'),\n",
    "                                'endpoint_path': path,\n",
    "                                'methods': list(methods.keys()) if methods else []\n",
    "                            }\n",
    "                        })\n",
    "                    \n",
    "                    print(f\"   âœ… Loaded: {file_name} (API v{api_info.get('version', 'unknown')})\")\n",
    "                    print(f\"      - Created {len(paths) + 1} chunks ({len(paths)} endpoints + info)\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Error loading {file_name}: {str(e)}\")\n",
    "    \n",
    "    return documents\n",
    "\n",
    "# Load all documents with improved parsing\n",
    "raw_documents = load_documents_from_folder_improved(DOCUMENTS_PATH)\n",
    "\n",
    "# Display summary\n",
    "print(f\"\\nðŸ“Š Document Summary:\")\n",
    "print(f\"Total document chunks loaded: {len(raw_documents)}\")\n",
    "\n",
    "doc_types = {}\n",
    "for doc in raw_documents:\n",
    "    doc_type = doc['type']\n",
    "    doc_types[doc_type] = doc_types.get(doc_type, 0) + 1\n",
    "\n",
    "print(\"\\nDocument types:\")\n",
    "for dtype, count in doc_types.items():\n",
    "    print(f\"  - {dtype}: {count} chunks\")\n",
    "\n",
    "print(f\"\\nâœ… Documents loaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Process Documents into Chunks for Embedding\n",
    "\n",
    "Split documents into meaningful chunks for better retrieval.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Prepared 36 document chunks for embedding\n",
      "   - From 5 source files\n",
      "\n",
      "Chunk types:\n",
      "  - user_story_overview: 1\n",
      "  - acceptance_criteria: 1\n",
      "  - bug_report: 1\n",
      "  - unknown: 4\n",
      "  - prd_intro: 2\n",
      "  - prd_section: 27\n"
     ]
    }
   ],
   "source": [
    "# Process documents into chunks for embedding\n",
    "doc_texts = []\n",
    "doc_metadata = []\n",
    "\n",
    "for doc in raw_documents:\n",
    "    content = doc['content']\n",
    "    \n",
    "    if doc['type'] == 'text':  # User story\n",
    "        # Split by acceptance criteria if present\n",
    "        if 'Acceptance Criteria:' in content:\n",
    "            parts = content.split('Acceptance Criteria:')\n",
    "            \n",
    "            # Add the overview\n",
    "            if parts[0].strip():\n",
    "                doc_texts.append(parts[0].strip())\n",
    "                doc_metadata.append({\n",
    "                    'type': 'user_story_overview',\n",
    "                    'filename': doc['filename'],\n",
    "                    'doc_type': doc['metadata']['doc_type'],\n",
    "                    'source': doc['metadata']['source']\n",
    "                })\n",
    "            \n",
    "            # Add acceptance criteria\n",
    "            if len(parts) > 1:\n",
    "                criteria_text = f\"Acceptance Criteria:\\n{parts[1].strip()}\"\n",
    "                doc_texts.append(criteria_text)\n",
    "                doc_metadata.append({\n",
    "                    'type': 'acceptance_criteria',\n",
    "                    'filename': doc['filename'],\n",
    "                    'doc_type': doc['metadata']['doc_type'],\n",
    "                    'source': doc['metadata']['source']\n",
    "                })\n",
    "        else:\n",
    "            # Add as single chunk\n",
    "            doc_texts.append(content)\n",
    "            doc_metadata.append({\n",
    "                'type': doc['metadata']['doc_type'],\n",
    "                'filename': doc['filename'],\n",
    "                'source': doc['metadata']['source']\n",
    "            })\n",
    "    \n",
    "    elif doc['type'] == 'markdown':  # PRD\n",
    "        # Split by sections (## headers)\n",
    "        if '## ' in content:\n",
    "            sections = content.split('## ')\n",
    "            \n",
    "            # Add introduction if exists\n",
    "            if sections[0].strip():\n",
    "                doc_texts.append(sections[0].strip())\n",
    "                doc_metadata.append({\n",
    "                    'type': 'prd_intro',\n",
    "                    'filename': doc['filename'],\n",
    "                    'section': 'Introduction',\n",
    "                    'doc_type': doc['metadata']['doc_type'],\n",
    "                    'source': doc['metadata']['source']\n",
    "                })\n",
    "            \n",
    "            # Add each section\n",
    "            for section in sections[1:]:\n",
    "                if section.strip():\n",
    "                    section_lines = section.strip().split('\\n')\n",
    "                    section_title = section_lines[0].strip()\n",
    "                    full_section = f\"## {section.strip()}\"\n",
    "                    \n",
    "                    doc_texts.append(full_section)\n",
    "                    doc_metadata.append({\n",
    "                        'type': 'prd_section',\n",
    "                        'filename': doc['filename'],\n",
    "                        'section': section_title,\n",
    "                        'doc_type': doc['metadata']['doc_type'],\n",
    "                        'source': doc['metadata']['source']\n",
    "                    })\n",
    "        else:\n",
    "            # Add as single chunk\n",
    "            doc_texts.append(content)\n",
    "            doc_metadata.append({\n",
    "                'type': 'prd',\n",
    "                'filename': doc['filename'],\n",
    "                'doc_type': doc['metadata']['doc_type'],\n",
    "                'source': doc['metadata']['source']\n",
    "            })\n",
    "    \n",
    "    elif doc['type'] in ['api_endpoint', 'api_info']:\n",
    "        # API chunks are already properly formatted\n",
    "        doc_texts.append(content)\n",
    "        doc_metadata.append(doc['metadata'])\n",
    "    \n",
    "    else:\n",
    "        # Default: add as is\n",
    "        doc_texts.append(content)\n",
    "        doc_metadata.append(doc['metadata'])\n",
    "\n",
    "# Store processed documents\n",
    "documents = doc_texts\n",
    "\n",
    "print(f\"âœ… Prepared {len(documents)} document chunks for embedding\")\n",
    "print(f\"   - From {len(set(m.get('filename', 'unknown') for m in doc_metadata))} source files\")\n",
    "\n",
    "# Show chunk type distribution\n",
    "chunk_types = {}\n",
    "for meta in doc_metadata:\n",
    "    chunk_type = meta.get('type', 'unknown')\n",
    "    chunk_types[chunk_type] = chunk_types.get(chunk_type, 0) + 1\n",
    "\n",
    "print(\"\\nChunk types:\")\n",
    "for ctype, count in chunk_types.items():\n",
    "    print(f\"  - {ctype}: {count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Create Vector Database with FAISS\n",
    "\n",
    "Generate embeddings and build the FAISS index for semantic search.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded embedding model: all-MiniLM-L6-v2\n",
      "\n",
      "Generating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a8538f59fab414cbe0ce147eac94110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Generated embeddings with shape: (36, 384)\n",
      "âœ… Created FAISS index with 36 vectors\n",
      "   Dimension: 384\n",
      "\n",
      "ðŸ” Test Query: 'How to test user registration with email validation?'\n",
      "\n",
      "ðŸ“š Retrieved Documents:\n",
      "\n",
      "1. Type: prd_section\n",
      "   Source: test_plan_user_management.md\n",
      "   Score: 0.593\n",
      "   Preview: ## Registration Testing\n",
      "1. **Valid Registration Flow**\n",
      "   - Test with valid email, strong password\n",
      "   - Verify email verification process\n",
      "   - Confirm...\n",
      "\n",
      "2. Type: acceptance_criteria\n",
      "   Source: user_story_registration.txt\n",
      "   Score: 0.572\n",
      "   Preview: Acceptance Criteria:\n",
      "1. **Successful Registration:** Given a user is on the registration page, when they enter a unique email address, a valid passwor...\n",
      "\n",
      "3. Type: prd_section\n",
      "   Source: test_plan_user_management.md\n",
      "   Score: 0.492\n",
      "   Preview: ## 5. Test Data Requirements\n",
      "\n",
      "- Valid test email addresses\n",
      "- Test user accounts with different roles\n",
      "- Sample PHI data (anonymized)\n",
      "- Performance test...\n"
     ]
    }
   ],
   "source": [
    "# Initialize embedding model\n",
    "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "print(f\"âœ… Loaded embedding model: all-MiniLM-L6-v2\")\n",
    "\n",
    "# Generate embeddings\n",
    "print(\"\\nGenerating embeddings...\")\n",
    "embeddings = embedding_model.encode(documents, show_progress_bar=True)\n",
    "embeddings = embeddings.astype('float32')\n",
    "\n",
    "print(f\"âœ… Generated embeddings with shape: {embeddings.shape}\")\n",
    "\n",
    "# Create FAISS index\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(f\"âœ… Created FAISS index with {index.ntotal} vectors\")\n",
    "print(f\"   Dimension: {dimension}\")\n",
    "\n",
    "# Test retrieval function\n",
    "def retrieve_context(query: str, k: int = 5) -> List[Tuple[str, Dict, float]]:\n",
    "    \"\"\"\n",
    "    Retrieve relevant documents for a query\n",
    "    \n",
    "    Args:\n",
    "        query: Search query\n",
    "        k: Number of documents to retrieve\n",
    "    \n",
    "    Returns:\n",
    "        List of (document, metadata, similarity_score) tuples\n",
    "    \"\"\"\n",
    "    # Generate query embedding\n",
    "    query_embedding = embedding_model.encode([query]).astype('float32')\n",
    "    \n",
    "    # Search index\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    \n",
    "    # Prepare results\n",
    "    results = []\n",
    "    for dist, idx in zip(distances[0], indices[0]):\n",
    "        if idx < len(documents):\n",
    "            similarity = 1 / (1 + dist)  # Convert distance to similarity\n",
    "            results.append((documents[idx], doc_metadata[idx], similarity))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test retrieval\n",
    "test_query = \"How to test user registration with email validation?\"\n",
    "print(f\"\\nðŸ” Test Query: '{test_query}'\")\n",
    "results = retrieve_context(test_query, k=3)\n",
    "\n",
    "print(\"\\nðŸ“š Retrieved Documents:\")\n",
    "for i, (doc, meta, score) in enumerate(results, 1):\n",
    "    print(f\"\\n{i}. Type: {meta.get('type', 'unknown')}\")\n",
    "    print(f\"   Source: {meta.get('filename', 'unknown')}\")\n",
    "    print(f\"   Score: {score:.3f}\")\n",
    "    print(f\"   Preview: {doc[:150]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: FIXED RAG Pipeline with JSON Mode ðŸŽ¯\n",
    "\n",
    "This is the **core fix**: Using Gemini's JSON mode to guarantee valid JSON output!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FIXED RAG Test Case Generator initialized with JSON mode!\n",
      "   - Guaranteed valid JSON output\n",
      "   - Improved context formatting\n",
      "   - Robust error handling\n"
     ]
    }
   ],
   "source": [
    "class FixedRAGTestCaseGenerator:\n",
    "    \"\"\"\n",
    "    FIXED: Retrieval-Augmented Generation pipeline with guaranteed JSON output\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, index, documents, metadata, embedding_model):\n",
    "        self.index = index\n",
    "        self.documents = documents\n",
    "        self.metadata = metadata\n",
    "        self.embedding_model = embedding_model\n",
    "\n",
    "        \n",
    "        # CRITICAL FIX: Create model with JSON mode enabled\n",
    "        self.json_model = genai.GenerativeModel(\n",
    "            'gemini-2.5-flash',\n",
    "            generation_config=genai.GenerationConfig(\n",
    "                response_mime_type=\"application/json\"  # This guarantees JSON output!\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    def retrieve(self, query: str, k: int = 5) -> List[Tuple[str, Dict, float]]:\n",
    "        \"\"\"Retrieve relevant documents\"\"\"\n",
    "        query_embedding = self.embedding_model.encode([query]).astype('float32')\n",
    "        distances, indices = self.index.search(query_embedding, k)\n",
    "        \n",
    "        results = []\n",
    "        for dist, idx in zip(distances[0], indices[0]):\n",
    "            if idx < len(self.documents):\n",
    "                similarity = 1 / (1 + dist)\n",
    "                results.append((self.documents[idx], self.metadata[idx], similarity))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def _build_context_string(self, context_docs: List) -> str:\n",
    "        \"\"\"IMPROVED: Build a more structured and clearer context string\"\"\"\n",
    "        context_parts = []\n",
    "        \n",
    "        for doc, meta, score in context_docs[:3]:  # Use top 3 most relevant\n",
    "            source_file = meta.get('filename', 'Unknown')\n",
    "            doc_type = meta.get('type', 'document').replace('_', ' ').title()\n",
    "            \n",
    "            # Add clear headers for each piece of context\n",
    "            context_parts.append(f\"--- CONTEXT FROM: {source_file} (Type: {doc_type}, Relevance: {score:.2%}) ---\")\n",
    "            context_parts.append(doc[:800])  # Limit each context chunk\n",
    "            context_parts.append(\"--- END OF CONTEXT ---\")\n",
    "        \n",
    "        return \"\\n\\n\".join(context_parts)\n",
    "    \n",
    "    def generate_test_case(self, requirement: str, num_context: int = 5) -> Dict:\n",
    "        \"\"\"\n",
    "        FIXED: Generate a test case using RAG with guaranteed JSON output\n",
    "        \n",
    "        Args:\n",
    "            requirement: The requirement to generate a test case for\n",
    "            num_context: Number of context documents to retrieve\n",
    "        \n",
    "        Returns:\n",
    "            Generated test case as a dictionary\n",
    "        \"\"\"\n",
    "        # Step 1: Retrieve relevant context\n",
    "        context_docs = self.retrieve(requirement, k=num_context)\n",
    "        \n",
    "        # Step 2: Build structured context string\n",
    "        context_str = self._build_context_string(context_docs)\n",
    "        \n",
    "        # Step 3: Create prompt\n",
    "        prompt = f\"\"\"You are a software testing expert. Generate a comprehensive test case for the following requirement.\n",
    "\n",
    "REQUIREMENT:\n",
    "{requirement}\n",
    "\n",
    "RELEVANT CONTEXT FROM PROJECT DOCUMENTS:\n",
    "{context_str}\n",
    "\n",
    "Generate a test case with ALL of these fields:\n",
    "- id: Unique test case ID (format: TC_XXX)\n",
    "- title: Clear, descriptive title\n",
    "- description: Detailed description of what is being tested\n",
    "- category: One of [Functional, Security, Integration, Performance, Usability]\n",
    "- priority: One of [Critical, High, Medium, Low]\n",
    "- compliance: Array of relevant standards (e.g., [\"HIPAA\", \"GDPR\", \"FDA\"])\n",
    "- preconditions: What must be true before testing (string)\n",
    "- test_steps: Array of detailed step-by-step instructions\n",
    "- expected_results: Specific expected outcomes (string)\n",
    "- test_data: Sample data needed for testing (string)\n",
    "- edge_cases: Array of special scenarios to consider\n",
    "- automation_feasible: Boolean indicating if this can be automated\n",
    "- estimated_duration: Estimated time to execute (e.g., \"5 minutes\")\n",
    "\n",
    "Use the context provided to make the test case specific and relevant to the actual project.\n",
    "Return ONLY a valid JSON object with these exact fields.\n",
    "\"\"\"\n",
    "        \n",
    "        # Step 4: Generate with JSON mode enabled\n",
    "        try:\n",
    "            response = self.json_model.generate_content(\n",
    "                prompt,\n",
    "                generation_config={\n",
    "                    'temperature': 0.3,\n",
    "                    'top_p': 0.9,\n",
    "                    'top_k': 30,\n",
    "                    'max_output_tokens': 1500,\n",
    "                },\n",
    "                safety_settings=safety_settings\n",
    "            )\n",
    "            \n",
    "            # SIMPLE PARSING - Just json.loads()!\n",
    "            test_case = json.loads(response.text)\n",
    "            \n",
    "            # Validate it's a proper test case\n",
    "            if not isinstance(test_case, dict) or 'id' not in test_case:\n",
    "                raise ValueError(\"Invalid test case structure\")\n",
    "            \n",
    "            # Add metadata about generation\n",
    "            test_case['generated_from'] = requirement[:100]\n",
    "            test_case['context_sources'] = [meta.get('filename', 'Unknown') \n",
    "                                           for _, meta, _ in context_docs[:3]]\n",
    "            test_case['generation_timestamp'] = datetime.now().isoformat()\n",
    "            \n",
    "            return test_case\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Generation error: {str(e)[:100]}\")\n",
    "            # Fallback for safety\n",
    "            return self._create_fallback_test_case(requirement, context_docs)\n",
    "    \n",
    "    def _create_fallback_test_case(self, requirement: str, context_docs: List) -> Dict:\n",
    "        \"\"\"Create a basic test case when generation fails\"\"\"\n",
    "        return {\n",
    "            'id': f'TC_{datetime.now().strftime(\"%H%M%S\")}',\n",
    "            'title': f'Test: {requirement[:60]}...',\n",
    "            'description': f'Verify that {requirement}',\n",
    "            'category': 'Functional',\n",
    "            'priority': 'Medium',\n",
    "            'compliance': ['General'],\n",
    "            'preconditions': 'System is in stable state',\n",
    "            'test_steps': [\n",
    "                'Setup test environment',\n",
    "                'Execute test scenario',\n",
    "                'Verify results'\n",
    "            ],\n",
    "            'expected_results': 'System behaves as specified in requirement',\n",
    "            'test_data': 'Standard test data set',\n",
    "            'edge_cases': [],\n",
    "            'automation_feasible': False,\n",
    "            'estimated_duration': '10 minutes',\n",
    "            'generated_from': requirement[:100],\n",
    "            'context_sources': [meta.get('filename', 'Unknown') for _, meta, _ in context_docs[:2]],\n",
    "            'generation_timestamp': datetime.now().isoformat(),\n",
    "            'fallback': True\n",
    "        }\n",
    "    \n",
    "    def batch_generate(self, requirements: List[str], progress: bool = True) -> List[Dict]:\n",
    "        \"\"\"Generate test cases for multiple requirements\"\"\"\n",
    "        test_cases = []\n",
    "        \n",
    "        iterator = tqdm(requirements, desc=\"Generating test cases\") if progress else requirements\n",
    "        \n",
    "        for req in iterator:\n",
    "            if progress:\n",
    "                iterator.set_description(f\"Processing: {req[:40]}...\")\n",
    "            \n",
    "            test_case = self.generate_test_case(req)\n",
    "            test_cases.append(test_case)\n",
    "            \n",
    "            # Brief delay to avoid rate limiting\n",
    "            import time\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        return test_cases\n",
    "    \n",
    "    def evaluate_generation(self, test_case: Dict) -> Dict:\n",
    "        \"\"\"Evaluate the quality of a generated test case\"\"\"\n",
    "        evaluation = {\n",
    "            'completeness': 0,\n",
    "            'detail_level': 0,\n",
    "            'context_usage': 0,\n",
    "            'specificity': 0,\n",
    "            'overall_score': 0\n",
    "        }\n",
    "        \n",
    "        # Check completeness\n",
    "        required_fields = ['id', 'title', 'description', 'test_steps', 'expected_results', \n",
    "                          'category', 'priority', 'preconditions']\n",
    "        present_fields = sum(1 for field in required_fields if test_case.get(field))\n",
    "        evaluation['completeness'] = present_fields / len(required_fields)\n",
    "        \n",
    "        # Check detail level\n",
    "        if test_case.get('test_steps'):\n",
    "            evaluation['detail_level'] = min(len(test_case['test_steps']) / 5, 1.0)\n",
    "        \n",
    "        # Check context usage\n",
    "        if test_case.get('context_sources') and not test_case.get('fallback'):\n",
    "            evaluation['context_usage'] = 1.0\n",
    "        \n",
    "        # Check specificity (not generic)\n",
    "        generic_terms = ['standard', 'general', 'basic', 'simple']\n",
    "        text = str(test_case).lower()\n",
    "        generic_count = sum(1 for term in generic_terms if term in text)\n",
    "        evaluation['specificity'] = max(0, 1 - (generic_count / 10))\n",
    "        \n",
    "        # Calculate overall score\n",
    "        evaluation['overall_score'] = sum(evaluation.values()) / 4\n",
    "        \n",
    "        return evaluation\n",
    "\n",
    "# Initialize the FIXED RAG pipeline\n",
    "rag_generator = FixedRAGTestCaseGenerator(\n",
    "    index=index,\n",
    "    documents=documents,\n",
    "    metadata=doc_metadata,\n",
    "    embedding_model=embedding_model\n",
    ")\n",
    "\n",
    "print(\"âœ… FIXED RAG Test Case Generator initialized with JSON mode!\")\n",
    "print(\"   - Guaranteed valid JSON output\")\n",
    "print(\"   - Improved context formatting\")\n",
    "print(\"   - Robust error handling\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Test the Fixed Pipeline ðŸŽ¯\n",
    "\n",
    "Let's test the fixed generator to see the improvement!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ§ª TEST 1: User Registration Test Case\n",
      "============================================================\n",
      "\n",
      "ðŸ“‹ Requirement: Test user registration with valid email and password meeting all acceptance criteria\n",
      "\n",
      "ðŸ” Retrieving relevant context...\n",
      "Found 3 relevant documents:\n",
      "  1. user_story_registration.txt - acceptance_criteria (Score: 59.89%)\n",
      "  2. test_plan_user_management.md - prd_section (Score: 59.65%)\n",
      "  3. prd_account_management.md - prd_section (Score: 51.64%)\n",
      "\n",
      "âš¡ Generating test case with FIXED JSON mode...\n",
      "âš ï¸ Generation error: Unterminated string starting at: line 29 column 5 (char 2192)\n",
      "âš ï¸ Used fallback generation\n",
      "\n",
      "ðŸ“„ Generated Test Case:\n",
      "----------------------------------------\n",
      "\n",
      "ID: TC_FB_0001\n",
      "\n",
      "TITLE: Test: Test user registration with valid email and password meeting...\n",
      "\n",
      "DESCRIPTION: Verify that Test user registration with valid email and password meeting all acceptance criteria\n",
      "\n",
      "CATEGORY: Functional\n",
      "\n",
      "PRIORITY: Medium\n",
      "\n",
      "COMPLIANCE:\n",
      "  â€¢ General\n",
      "\n",
      "PRECONDITIONS: System is in stable state\n",
      "\n",
      "TEST STEPS:\n",
      "  â€¢ Navigate to relevant module\n",
      "  â€¢ Perform required action\n",
      "  â€¢ Verify outcome\n",
      "\n",
      "EXPECTED RESULTS: System behaves as specified in requirement\n",
      "\n",
      "TEST DATA: {'placeholder': 'Add specific test data'}\n",
      "\n",
      "EDGE CASES: []\n",
      "\n",
      "AUTOMATION FEASIBLE: False\n",
      "\n",
      "ESTIMATED DURATION: 10 minutes\n",
      "\n",
      "LOW CONTEXT CONFIDENCE: True\n",
      "\n",
      "ðŸ“Š Quality Metrics:\n",
      "  completeness    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ 100.00%\n",
      "  detail_level    â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 60.00%\n",
      "  context_usage   â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 0.00%\n",
      "  specificity     â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘ 90.00%\n",
      "  overall_score   â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘ 62.50%\n"
     ]
    }
   ],
   "source": [
    "# Test Case 1: User Registration\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ§ª TEST 1: User Registration Test Case\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "requirement_1 = \"Test user registration with valid email and password meeting all acceptance criteria\"\n",
    "\n",
    "print(f\"\\nðŸ“‹ Requirement: {requirement_1}\")\n",
    "print(\"\\nðŸ” Retrieving relevant context...\")\n",
    "\n",
    "# Retrieve context\n",
    "context_docs = rag_generator.retrieve(requirement_1, k=3)\n",
    "print(f\"Found {len(context_docs)} relevant documents:\")\n",
    "\n",
    "for i, (doc, meta, score) in enumerate(context_docs, 1):\n",
    "    print(f\"  {i}. {meta.get('filename', 'Unknown')} - {meta.get('type', 'unknown')} (Score: {score:.2%})\")\n",
    "\n",
    "print(\"\\nâš¡ Generating test case with FIXED JSON mode...\")\n",
    "test_case_1 = rag_generator.generate_test_case(requirement_1)\n",
    "\n",
    "# Check if it's a fallback\n",
    "if test_case_1.get('fallback'):\n",
    "    print(\"âš ï¸ Used fallback generation\")\n",
    "else:\n",
    "    print(\"âœ… Successfully generated with JSON mode!\")\n",
    "\n",
    "# Display the test case\n",
    "print(\"\\nðŸ“„ Generated Test Case:\")\n",
    "print(\"-\" * 40)\n",
    "for key, value in test_case_1.items():\n",
    "    if key not in ['generated_from', 'context_sources', 'generation_timestamp', 'fallback']:\n",
    "        if isinstance(value, list) and len(value) > 0:\n",
    "            print(f\"\\n{key.upper().replace('_', ' ')}:\")\n",
    "            for item in value:\n",
    "                print(f\"  â€¢ {item}\")\n",
    "        else:\n",
    "            print(f\"\\n{key.upper().replace('_', ' ')}: {value}\")\n",
    "\n",
    "# Evaluate quality\n",
    "evaluation = rag_generator.evaluate_generation(test_case_1)\n",
    "print(\"\\nðŸ“Š Quality Metrics:\")\n",
    "for metric, score in evaluation.items():\n",
    "    bar = \"â–ˆ\" * int(score * 10) + \"â–‘\" * (10 - int(score * 10))\n",
    "    print(f\"  {metric:15} {bar} {score:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Batch Generation with the Fixed Pipeline\n",
    "\n",
    "Generate multiple test cases to demonstrate reliability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Generating 8 test cases with FIXED pipeline...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Test successful user registration with a...:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Generation error: Unterminated string starting at: line 27 column 5 (char 1822)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Test password reset token expiration aft...:  12%|â–ˆâ–Ž        | 1/8 [02:27<17:11, 147.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Generation error: Unterminated string starting at: line 30 column 5 (char 2168)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Verify HIPAA compliance for patient data...:  25%|â–ˆâ–ˆâ–Œ       | 2/8 [02:49<07:21, 73.53s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Generation error: Invalid operation: The `response.text` quick accessor requires the response to contain a valid `Part\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Test API authentication with invalid JWT...:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 3/8 [02:58<03:41, 44.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Generation error: Unterminated string starting at: line 14 column 5 (char 1214)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Validate password strength requirements ...:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 4/8 [03:08<02:02, 30.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Generation error: Expecting property name enclosed in double quotes: line 21 column 1 (char 2347)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Test concurrent user registration from m...:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 5/8 [03:17<01:08, 22.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸ Generation error: Unterminated string starting at: line 13 column 5 (char 1847)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: Verify audit trail generation for sensit...:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 6/8 [03:34<01:11, 35.69s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mðŸš€ Generating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_requirements)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m test cases with FIXED pipeline...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Generate test cases\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m generated_test_cases = \u001b[43mrag_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_requirements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Analyze results\u001b[39;00m\n\u001b[32m     19\u001b[39m successful = \u001b[38;5;28msum\u001b[39m(\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m tc \u001b[38;5;129;01min\u001b[39;00m generated_test_cases \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tc.get(\u001b[33m'\u001b[39m\u001b[33mfallback\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 214\u001b[39m, in \u001b[36mFixedRAGTestCaseGenerator.batch_generate\u001b[39m\u001b[34m(self, requirements, progress)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m progress:\n\u001b[32m    212\u001b[39m     iterator.set_description(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProcessing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreq[:\u001b[32m40\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m test_case = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_test_case\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    215\u001b[39m test_cases.append(test_case)\n\u001b[32m    217\u001b[39m \u001b[38;5;66;03m# Brief delay to avoid rate limiting\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36mFixedRAGTestCaseGenerator.generate_test_case\u001b[39m\u001b[34m(self, requirement, num_context)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;66;03m# Step 4: Generate with JSON mode enabled\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjson_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m        \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafety_settings\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;66;03m# Parse JSON\u001b[39;00m\n\u001b[32m    116\u001b[39m     test_case = json.loads(response.text)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/generativeai/generative_models.py:331\u001b[39m, in \u001b[36mGenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_iterator(iterator)\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_response(response)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    834\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:76\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(callable_)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34merror_remapped_callable\u001b[39m(*args, **kwargs):\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/grpc/_interceptor.py:277\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    269\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    270\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    276\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     response, ignored_call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/grpc/_interceptor.py:329\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys.exc_info()[\u001b[32m2\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interceptor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m call.result(), call\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:79\u001b[39m, in \u001b[36m_LoggingClientInterceptor.intercept_unary_unary\u001b[39m\u001b[34m(self, continuation, client_call_details, request)\u001b[39m\n\u001b[32m     64\u001b[39m     grpc_request = {\n\u001b[32m     65\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpayload\u001b[39m\u001b[33m\"\u001b[39m: request_payload,\n\u001b[32m     66\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrequestMethod\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgrpc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[32m     68\u001b[39m     }\n\u001b[32m     69\u001b[39m     _LOGGER.debug(\n\u001b[32m     70\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details.method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     71\u001b[39m         extra={\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m         },\n\u001b[32m     77\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m response = \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[32m     81\u001b[39m     response_metadata = response.trailing_metadata()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/grpc/_interceptor.py:315\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[39m\u001b[34m(new_details, request)\u001b[39m\n\u001b[32m    306\u001b[39m (\n\u001b[32m    307\u001b[39m     new_method,\n\u001b[32m    308\u001b[39m     new_timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m    312\u001b[39m     new_compression,\n\u001b[32m    313\u001b[39m ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     response, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/grpc/_channel.py:1189\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwith_call\u001b[39m(\n\u001b[32m   1181\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1182\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1187\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1188\u001b[39m ) -> Tuple[Any, grpc.Call]:\n\u001b[32m-> \u001b[39m\u001b[32m1189\u001b[39m     state, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/grpc/_channel.py:1162\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._blocking\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1145\u001b[39m state.target = _common.decode(\u001b[38;5;28mself\u001b[39m._target)\n\u001b[32m   1146\u001b[39m call = \u001b[38;5;28mself\u001b[39m._channel.segregated_call(\n\u001b[32m   1147\u001b[39m     cygrpc.PropagationConstants.GRPC_PROPAGATE_DEFAULTS,\n\u001b[32m   1148\u001b[39m     \u001b[38;5;28mself\u001b[39m._method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1160\u001b[39m     \u001b[38;5;28mself\u001b[39m._registered_call_handle,\n\u001b[32m   1161\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m event = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1163\u001b[39m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m._response_deserializer)\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[39m, in \u001b[36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:97\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:80\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._internal_latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Define comprehensive test requirements\n",
    "test_requirements = [\n",
    "    \"Test successful user registration with all required fields\",\n",
    "    \"Test password reset token expiration after 24 hours\",\n",
    "    \"Verify HIPAA compliance for patient data handling\",\n",
    "    \"Test API authentication with invalid JWT token\",\n",
    "    \"Validate password strength requirements with special characters\",\n",
    "    \"Test concurrent user registration from multiple sessions\",\n",
    "    \"Verify audit trail generation for sensitive data access\",\n",
    "    \"Test API rate limiting for registration endpoint\"\n",
    "]\n",
    "\n",
    "print(f\"ðŸš€ Generating {len(test_requirements)} test cases with FIXED pipeline...\\n\")\n",
    "\n",
    "# Generate test cases\n",
    "generated_test_cases = rag_generator.batch_generate(test_requirements, progress=True)\n",
    "\n",
    "# Analyze results\n",
    "successful = sum(1 for tc in generated_test_cases if not tc.get('fallback', False))\n",
    "print(f\"\\nâœ… Generation Complete!\")\n",
    "print(f\"   - Successful: {successful}/{len(generated_test_cases)} ({successful/len(generated_test_cases)*100:.1f}%)\")\n",
    "print(f\"   - Fallbacks: {len(generated_test_cases) - successful}\")\n",
    "\n",
    "# Analyze categories and priorities\n",
    "categories = {}\n",
    "priorities = {}\n",
    "compliance_standards = set()\n",
    "\n",
    "for tc in generated_test_cases:\n",
    "    if not tc.get('fallback'):\n",
    "        categories[tc.get('category', 'Unknown')] = categories.get(tc.get('category', 'Unknown'), 0) + 1\n",
    "        priorities[tc.get('priority', 'Unknown')] = priorities.get(tc.get('priority', 'Unknown'), 0) + 1\n",
    "        if tc.get('compliance'):\n",
    "            compliance_standards.update(tc['compliance'])\n",
    "\n",
    "print(\"\\nðŸ“Š Test Case Distribution:\")\n",
    "print(f\"\\nCategories: {dict(categories)}\")\n",
    "print(f\"Priorities: {dict(priorities)}\")\n",
    "print(f\"Compliance Standards: {list(compliance_standards)}\")\n",
    "\n",
    "# Calculate average quality\n",
    "total_quality = 0\n",
    "for tc in generated_test_cases:\n",
    "    if not tc.get('fallback'):\n",
    "        eval_score = rag_generator.evaluate_generation(tc)\n",
    "        total_quality += eval_score['overall_score']\n",
    "\n",
    "if successful > 0:\n",
    "    avg_quality = total_quality / successful\n",
    "    print(f\"\\nðŸ† Average Quality Score: {avg_quality:.2%}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Export Generated Test Cases ðŸ“\n",
    "\n",
    "Save the test cases in multiple formats for use in test management tools.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Saved JSON: /Users/shtlpmac036/Documents/Personal/GenAI Hack /data/generated_test_cases/test_cases_fixed_20250914_231800.json\n",
      "âœ… Saved CSV: /Users/shtlpmac036/Documents/Personal/GenAI Hack /data/generated_test_cases/test_cases_fixed_20250914_231800.csv\n",
      "   - 8 test cases exported\n",
      "âœ… Saved Markdown Report: /Users/shtlpmac036/Documents/Personal/GenAI Hack /data/generated_test_cases/test_report_fixed_20250914_231800.md\n",
      "\n",
      "ðŸ“ All files saved to: /Users/shtlpmac036/Documents/Personal/GenAI Hack /data/generated_test_cases\n",
      "\n",
      "ðŸ“Š Export Summary:\n",
      "  - JSON: All 8 test cases\n",
      "  - CSV: 8 non-fallback test cases\n",
      "  - Markdown: Detailed report with 8 test cases\n",
      "\n",
      "ðŸ“‹ Sample Test Case from Export:\n",
      "  ID: TC_001\n",
      "  Title: Successful User Registration with Valid Data\n",
      "  Category: Functional\n",
      "  Priority: High\n",
      "  Description: Verify successful user registration with all required fields using valid data.\n",
      "  Preconditions: A clean database with no pre-existing user accounts.  The registration page should be accessible.\n",
      "  Expected Results: The system should create a new user account with the provided details. The user should be automatically logged in. A success message should be displayed (e.g., 'Account created successfully!'). A verification email should be sent to the registered email address.\n",
      "  Test Data: email: testuser1@example.com, password: Password123!\n",
      "  Automation Feasible: True\n",
      "  Duration: 5 minutes\n",
      "  Compliance: GDPR\n",
      "\n",
      "ðŸ’¡ TIP: Open the CSV in Excel or import the JSON into your test management tool!\n"
     ]
    }
   ],
   "source": [
    "# Create output directory\n",
    "output_dir = \"/Users/shtlpmac036/Documents/Personal/GenAI Hack /data/generated_test_cases\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# 1. Save as JSON\n",
    "json_file = os.path.join(output_dir, f\"test_cases_fixed_{timestamp}.json\")\n",
    "with open(json_file, 'w') as f:\n",
    "    json.dump(generated_test_cases, f, indent=2, default=str)\n",
    "print(f\"âœ… Saved JSON: {json_file}\")\n",
    "\n",
    "# 2. Save as CSV\n",
    "df_data = []\n",
    "for tc in generated_test_cases:\n",
    "    if not tc.get('fallback'):\n",
    "        df_data.append({\n",
    "            'ID': tc.get('id'),\n",
    "            'Title': tc.get('title'),\n",
    "            'Category': tc.get('category'),\n",
    "            'Priority': tc.get('priority'),\n",
    "            'Description': tc.get('description'),\n",
    "            'Preconditions': tc.get('preconditions'),\n",
    "            'Steps': '; '.join(tc.get('test_steps', [])),\n",
    "            'Expected Results': tc.get('expected_results'),\n",
    "            'Test Data': tc.get('test_data'),\n",
    "            'Automation Feasible': tc.get('automation_feasible'),\n",
    "            'Duration': tc.get('estimated_duration'),\n",
    "            'Compliance': ', '.join(tc.get('compliance', []))\n",
    "        })\n",
    "\n",
    "if df_data:\n",
    "    df = pd.DataFrame(df_data)\n",
    "    csv_file = os.path.join(output_dir, f\"test_cases_fixed_{timestamp}.csv\")\n",
    "    df.to_csv(csv_file, index=False)\n",
    "    print(f\"âœ… Saved CSV: {csv_file}\")\n",
    "    print(f\"   - {len(df_data)} test cases exported\")\n",
    "\n",
    "# 3. Create Markdown report\n",
    "md_file = os.path.join(output_dir, f\"test_report_fixed_{timestamp}.md\")\n",
    "with open(md_file, 'w') as f:\n",
    "    f.write(\"# Test Cases Report (FIXED Pipeline)\\n\\n\")\n",
    "    f.write(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Total Test Cases: {len(generated_test_cases)}\\n\")\n",
    "    f.write(f\"Successful Generation: {successful}/{len(generated_test_cases)}\\n\\n\")\n",
    "    \n",
    "    f.write(\"## Test Cases\\n\\n\")\n",
    "    \n",
    "    for tc in generated_test_cases:\n",
    "        if not tc.get('fallback'):\n",
    "            f.write(f\"### {tc.get('id')}: {tc.get('title')}\\n\\n\")\n",
    "            f.write(f\"**Category:** {tc.get('category')} | \")\n",
    "            f.write(f\"**Priority:** {tc.get('priority')} | \")\n",
    "            f.write(f\"**Duration:** {tc.get('estimated_duration')}\\n\\n\")\n",
    "            \n",
    "            f.write(f\"**Description:** {tc.get('description')}\\n\\n\")\n",
    "            \n",
    "            if tc.get('preconditions'):\n",
    "                f.write(f\"**Preconditions:** {tc.get('preconditions')}\\n\\n\")\n",
    "            \n",
    "            f.write(\"**Test Steps:**\\n\")\n",
    "            for i, step in enumerate(tc.get('test_steps', []), 1):\n",
    "                f.write(f\"{i}. {step}\\n\")\n",
    "            \n",
    "            f.write(f\"\\n**Expected Results:** {tc.get('expected_results')}\\n\")\n",
    "            \n",
    "            if tc.get('test_data'):\n",
    "                f.write(f\"\\n**Test Data:** {tc.get('test_data')}\\n\")\n",
    "            \n",
    "            if tc.get('edge_cases'):\n",
    "                f.write(\"\\n**Edge Cases:**\\n\")\n",
    "                for edge in tc.get('edge_cases'):\n",
    "                    f.write(f\"- {edge}\\n\")\n",
    "            \n",
    "            if tc.get('compliance'):\n",
    "                f.write(f\"\\n**Compliance:** {', '.join(tc['compliance'])}\\n\")\n",
    "            \n",
    "            f.write(f\"\\n**Automation Feasible:** {'Yes' if tc.get('automation_feasible') else 'No'}\\n\")\n",
    "            \n",
    "            f.write(\"\\n---\\n\\n\")\n",
    "\n",
    "print(f\"âœ… Saved Markdown Report: {md_file}\")\n",
    "\n",
    "# 4. Display summary\n",
    "print(f\"\\nðŸ“ All files saved to: {output_dir}\")\n",
    "print(\"\\nðŸ“Š Export Summary:\")\n",
    "print(f\"  - JSON: All {len(generated_test_cases)} test cases\")\n",
    "print(f\"  - CSV: {len(df_data)} non-fallback test cases\")\n",
    "print(f\"  - Markdown: Detailed report with {len(df_data)} test cases\")\n",
    "\n",
    "# Show a sample\n",
    "if df_data:\n",
    "    print(\"\\nðŸ“‹ Sample Test Case from Export:\")\n",
    "    sample = df_data[0]\n",
    "    for key, value in sample.items():\n",
    "        if key != 'Steps':  # Skip long field\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nðŸ’¡ TIP: Open the CSV in Excel or import the JSON into your test management tool!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŽ® Interactive: Generate Your Own Test Case\n",
    "\n",
    "Try the fixed pipeline with your own requirement!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸŽ® INTERACTIVE TEST CASE GENERATOR\n",
      "============================================================\n",
      "\n",
      "ðŸ“‹ Your Requirement:\n",
      "\n",
      "Test the password complexity validation with the following rules:\n",
      "- Minimum 8 characters\n",
      "- At least one uppercase letter  \n",
      "- At least one number\n",
      "- At least one special character\n",
      "- Password should not contain username\n",
      "\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "âš¡ Generating with FIXED JSON mode...\n",
      "âœ… Successfully generated with JSON mode!\n",
      "\n",
      "ðŸ’¾ Saved to: /Users/shtlpmac036/Documents/Personal/GenAI Hack /data/generated_test_cases/custom_test_case_20250914_231818.json\n",
      "\n",
      "ðŸ“„ GENERATED TEST CASE:\n",
      "============================================================\n",
      "\n",
      "ðŸ†” ID: TC_001\n",
      "ðŸ“ Title: Password Complexity Validation\n",
      "ðŸ·ï¸  Category: Functional\n",
      "âš¡ Priority: High\n",
      "â±ï¸  Duration: 15 minutes\n",
      "ðŸ¤– Automatable: True\n",
      "\n",
      "ðŸ“– Description:\n",
      "Verify password complexity validation with minimum length, uppercase, number, special character, and username exclusion rules.\n",
      "\n",
      "âš™ï¸  Preconditions:\n",
      "User is on the registration page.\n",
      "\n",
      "ðŸ“‹ Test Steps:\n",
      "  1. Step 1: Enter a password less than 8 characters and attempt registration.\n",
      "  2. Step 2: Enter a password with no uppercase letters and attempt registration.\n",
      "  3. Step 3: Enter a password with no numbers and attempt registration.\n",
      "  4. Step 4: Enter a password with no special characters and attempt registration.\n",
      "  5. Step 5: Enter a password that contains the username and attempt registration.\n",
      "  6. Step 6: Enter a valid password meeting all criteria and attempt registration.\n",
      "\n",
      "âœ… Expected Results:\n",
      "Step 1-5 should result in an error message indicating the password does not meet complexity requirements. Step 6 should result in successful registration.\n",
      "\n",
      "ðŸ“Š Test Data:\n",
      "Username: testuser, Passwords: test, Test1, Test!, Test1!, Test1!Testuser, TestUser1234!\n",
      "\n",
      "âš ï¸  Edge Cases:\n",
      "  â€¢ Password with maximum allowed length\n",
      "  â€¢ Password with Unicode characters\n",
      "  â€¢ Password with unusual special characters\n",
      "\n",
      "ðŸ“Š Quality Score: 100.00%\n",
      "\n",
      "============================================================\n",
      "ðŸ’¡ TIP: Modify the 'custom_requirement' variable above and re-run!\n",
      "ðŸ’¡ Your test case is automatically saved in the output directory!\n"
     ]
    }
   ],
   "source": [
    "# ðŸŽ® INTERACTIVE TEST CASE GENERATOR (FIXED VERSION)\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸŽ® INTERACTIVE TEST CASE GENERATOR\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# MODIFY THIS REQUIREMENT TO GENERATE YOUR OWN TEST CASE\n",
    "custom_requirement = \"\"\"\n",
    "Test the password complexity validation with the following rules:\n",
    "- Minimum 8 characters\n",
    "- At least one uppercase letter  \n",
    "- At least one number\n",
    "- At least one special character\n",
    "- Password should not contain username\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\nðŸ“‹ Your Requirement:\\n{custom_requirement}\")\n",
    "print(\"\\n\" + \"-\"*50)\n",
    "\n",
    "# Generate test case\n",
    "print(\"\\nâš¡ Generating with FIXED JSON mode...\")\n",
    "custom_test_case = rag_generator.generate_test_case(custom_requirement)\n",
    "\n",
    "if not custom_test_case.get('fallback'):\n",
    "    print(\"âœ… Successfully generated with JSON mode!\\n\")\n",
    "    \n",
    "    # Option to save this individual test case\n",
    "    save_individual = True  # Set to True to save\n",
    "    \n",
    "    if save_individual:\n",
    "        individual_file = os.path.join(output_dir, f\"custom_test_case_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
    "        with open(individual_file, 'w') as f:\n",
    "            json.dump(custom_test_case, f, indent=2, default=str)\n",
    "        print(f\"ðŸ’¾ Saved to: {individual_file}\\n\")\n",
    "else:\n",
    "    print(\"âš ï¸ Used fallback generation\\n\")\n",
    "\n",
    "# Display the test case\n",
    "print(\"ðŸ“„ GENERATED TEST CASE:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nðŸ†” ID: {custom_test_case.get('id')}\")\n",
    "print(f\"ðŸ“ Title: {custom_test_case.get('title')}\")\n",
    "print(f\"ðŸ·ï¸  Category: {custom_test_case.get('category')}\")\n",
    "print(f\"âš¡ Priority: {custom_test_case.get('priority')}\")\n",
    "print(f\"â±ï¸  Duration: {custom_test_case.get('estimated_duration')}\")\n",
    "print(f\"ðŸ¤– Automatable: {custom_test_case.get('automation_feasible')}\")\n",
    "\n",
    "print(f\"\\nðŸ“– Description:\\n{custom_test_case.get('description')}\")\n",
    "\n",
    "if custom_test_case.get('preconditions'):\n",
    "    print(f\"\\nâš™ï¸  Preconditions:\\n{custom_test_case.get('preconditions')}\")\n",
    "\n",
    "print(\"\\nðŸ“‹ Test Steps:\")\n",
    "for i, step in enumerate(custom_test_case.get('test_steps', []), 1):\n",
    "    print(f\"  {i}. {step}\")\n",
    "\n",
    "print(f\"\\nâœ… Expected Results:\\n{custom_test_case.get('expected_results')}\")\n",
    "\n",
    "if custom_test_case.get('test_data'):\n",
    "    print(f\"\\nðŸ“Š Test Data:\\n{custom_test_case.get('test_data')}\")\n",
    "\n",
    "if custom_test_case.get('edge_cases'):\n",
    "    print(\"\\nâš ï¸  Edge Cases:\")\n",
    "    for edge in custom_test_case.get('edge_cases', []):\n",
    "        print(f\"  â€¢ {edge}\")\n",
    "\n",
    "if custom_test_case.get('compliance'):\n",
    "    print(f\"\\nðŸ¥ Compliance: {', '.join(custom_test_case.get('compliance', []))}\")\n",
    "\n",
    "# Quality check\n",
    "quality = rag_generator.evaluate_generation(custom_test_case)\n",
    "print(f\"\\nðŸ“Š Quality Score: {quality['overall_score']:.2%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸ’¡ TIP: Modify the 'custom_requirement' variable above and re-run!\")\n",
    "print(\"ðŸ’¡ Your test case is automatically saved in the output directory!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
