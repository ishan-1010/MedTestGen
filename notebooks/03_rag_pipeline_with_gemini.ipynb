{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RAG Pipeline for Healthcare Test Case Generation with Gemini\n",
        "\n",
        "This notebook implements a Retrieval-Augmented Generation (RAG) pipeline that combines:\n",
        "1. **FAISS** for efficient semantic search and retrieval\n",
        "2. **Google Gemini** for intelligent generation based on retrieved context\n",
        "3. **Healthcare-specific** test case generation aligned with NASSCOM requirements\n",
        "\n",
        "## Key Features:\n",
        "- üîç Semantic retrieval of relevant test cases and requirements\n",
        "- ü§ñ Context-aware generation using Gemini Pro\n",
        "- üè• Healthcare compliance and standards integration\n",
        "- üìä Evaluation metrics for RAG performance\n",
        "- üöÄ Production-ready pipeline architecture\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Libraries imported successfully!\n",
            "Python version: 3.13.7 (main, Aug 14 2025, 11:12:11) [Clang 17.0.0 (clang-1700.0.13.3)]\n",
            "FAISS version: 1.12.0\n",
            "‚úÖ Gemini API key found in environment\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import faiss\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import google.generativeai as genai\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "from dataclasses import dataclass, asdict\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "from tqdm import tqdm\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n",
        "print(f\"Python version: {sys.version}\")\n",
        "print(f\"FAISS version: {faiss.__version__ if hasattr(faiss, '__version__') else 'Available'}\")\n",
        "\n",
        "# Check for Gemini API key\n",
        "if os.getenv('GEMINI_API_KEY'):\n",
        "    print(\"‚úÖ Gemini API key found in environment\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Warning: GEMINI_API_KEY not found in .env file\")\n",
        "    print(\"Please add your Gemini API key to the .env file\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Configure Gemini API\n",
        "\n",
        "We'll use Google's Gemini Pro model for generation. Gemini Pro offers:\n",
        "- Strong reasoning capabilities\n",
        "- Healthcare domain understanding\n",
        "- Support for structured output\n",
        "- Cost-effective pricing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Gemini API connected successfully!\n",
            "Test response: Hello!...\n",
            "‚úÖ Gemini model configured for healthcare test generation\n"
          ]
        }
      ],
      "source": [
        "# Configure Gemini\n",
        "genai.configure(api_key=os.getenv('GEMINI_API_KEY'))\n",
        "\n",
        "# Initialize Gemini model\n",
        "model = genai.GenerativeModel('gemini-2.5-flash')\n",
        "\n",
        "# Test Gemini connection\n",
        "try:\n",
        "    response = model.generate_content(\"Hello, Gemini! Respond with a brief greeting.\")\n",
        "    print(\"‚úÖ Gemini API connected successfully!\")\n",
        "    print(f\"Test response: {response.text[:100]}...\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error connecting to Gemini: {e}\")\n",
        "    print(\"Please check your API key in the .env file\")\n",
        "\n",
        "# Model configuration for healthcare test case generation\n",
        "generation_config = {\n",
        "    'temperature': 0.2,  \n",
        "    'top_p': 0.9,\n",
        "    'top_k': 40,\n",
        "    'max_output_tokens': 2048,\n",
        "}\n",
        "\n",
        "# Safety settings for healthcare content\n",
        "safety_settings = [\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\"\n",
        "    },\n",
        "    {\n",
        "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "        \"threshold\": \"BLOCK_NONE\"  # Allow medical content\n",
        "    }\n",
        "]\n",
        "\n",
        "print(\"‚úÖ Gemini model configured for healthcare test generation\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Build Knowledge Base\n",
        "\n",
        "Create a comprehensive knowledge base of healthcare test cases, requirements, and compliance standards that will be used for retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìÇ Loading documents from: /Users/shtlpmac036/Documents/Personal/GenAI Hack /data/documents\n",
            "Found 5 files\n",
            "   ‚úÖ Loaded: user_story_registration.txt\n",
            "   ‚úÖ Loaded: bug_report_template.txt\n",
            "   ‚úÖ Loaded: api_spec_v1.yaml (API v1.0.0)\n",
            "   ‚úÖ Loaded: test_plan_user_management.md\n",
            "   ‚úÖ Loaded: prd_account_management.md\n",
            "\n",
            "üìä Document Summary:\n",
            "Total documents loaded: 5\n",
            "  - user_story_registration.txt (text) - 2273 characters\n",
            "  - bug_report_template.txt (text) - 2884 characters\n",
            "  - api_spec_v1.yaml (api_spec) - 6467 characters\n",
            "  - test_plan_user_management.md (markdown) - 3971 characters\n",
            "  - prd_account_management.md (markdown) - 2931 characters\n",
            "\n",
            "‚úÖ Documents loaded successfully!\n",
            "   - User Stories, PRDs, and API Specs are now available for RAG pipeline\n",
            "   - These will be processed into embeddings for semantic search\n"
          ]
        }
      ],
      "source": [
        "# Load documents from files instead of hardcoded knowledge base\n",
        "import glob\n",
        "import yaml\n",
        "from pathlib import Path\n",
        "\n",
        "# Path to documents folder\n",
        "DOCUMENTS_PATH = \"/Users/shtlpmac036/Documents/Personal/GenAI Hack /data/documents\"\n",
        "\n",
        "# Function to load all documents from the folder\n",
        "def load_documents_from_folder(folder_path):\n",
        "    \"\"\"Load all documents from a folder and return as a list of dictionaries\"\"\"\n",
        "    documents = []\n",
        "    \n",
        "    # Get all files in the documents folder\n",
        "    document_files = glob.glob(f\"{folder_path}/*\")\n",
        "    \n",
        "    print(f\"üìÇ Loading documents from: {folder_path}\")\n",
        "    print(f\"Found {len(document_files)} files\")\n",
        "    \n",
        "    for file_path in document_files:\n",
        "        file_name = Path(file_path).name\n",
        "        file_extension = Path(file_path).suffix\n",
        "        \n",
        "        try:\n",
        "            if file_extension in ['.txt', '.md']:\n",
        "                # Load text and markdown files\n",
        "                with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                    content = f.read()\n",
        "                    documents.append({\n",
        "                        'filename': file_name,\n",
        "                        'type': 'text' if file_extension == '.txt' else 'markdown',\n",
        "                        'content': content,\n",
        "                        'metadata': {\n",
        "                            'source': file_path,\n",
        "                            'doc_type': 'user_story' if 'user_story' in file_name else \n",
        "                                       'prd' if 'prd' in file_name else 'general'\n",
        "                        }\n",
        "                    })\n",
        "                    print(f\"   ‚úÖ Loaded: {file_name}\")\n",
        "                    \n",
        "            elif file_extension in ['.yaml', '.yml']:\n",
        "                # Load YAML files (API specifications)\n",
        "                with open(file_path, 'r', encoding='utf-8') as f:\n",
        "                    yaml_content = yaml.safe_load(f)\n",
        "                    # Convert YAML to string for processing\n",
        "                    content_str = yaml.dump(yaml_content, default_flow_style=False)\n",
        "                    documents.append({\n",
        "                        'filename': file_name,\n",
        "                        'type': 'api_spec',\n",
        "                        'content': content_str,\n",
        "                        'metadata': {\n",
        "                            'source': file_path,\n",
        "                            'doc_type': 'api_specification',\n",
        "                            'api_version': yaml_content.get('info', {}).get('version', 'unknown')\n",
        "                        }\n",
        "                    })\n",
        "                    print(f\"   ‚úÖ Loaded: {file_name} (API v{yaml_content.get('info', {}).get('version', 'unknown')})\")\n",
        "                    \n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Error loading {file_name}: {str(e)}\")\n",
        "    \n",
        "    return documents\n",
        "\n",
        "# Load all documents\n",
        "documents = load_documents_from_folder(DOCUMENTS_PATH)\n",
        "\n",
        "# Display summary of loaded documents\n",
        "print(f\"\\nüìä Document Summary:\")\n",
        "print(f\"Total documents loaded: {len(documents)}\")\n",
        "for doc in documents:\n",
        "    print(f\"  - {doc['filename']} ({doc['type']}) - {len(doc['content'])} characters\")\n",
        "\n",
        "print(f\"\\n‚úÖ Documents loaded successfully!\")\n",
        "print(f\"   - User Stories, PRDs, and API Specs are now available for RAG pipeline\")\n",
        "print(f\"   - These will be processed into embeddings for semantic search\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## How to Add More Documents\n",
        "\n",
        "To expand your knowledge base, simply add more documents to the `/data/documents/` folder:\n",
        "\n",
        "1. **User Stories**: Save as `.txt` files with acceptance criteria\n",
        "2. **PRDs**: Save as `.md` files with proper markdown formatting\n",
        "3. **API Specs**: Save as `.yaml` or `.yml` files in OpenAPI format\n",
        "\n",
        "The system will automatically:\n",
        "- Load and parse the documents\n",
        "- Split them into meaningful chunks\n",
        "- Generate embeddings for semantic search\n",
        "- Make them available for RAG-based test generation\n",
        "\n",
        "This approach makes your system production-ready and demonstrates how it would work with real project documentation in the hackathon!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Create Vector Database for Retrieval\n",
        "\n",
        "Build FAISS index with embeddings of all knowledge base documents for efficient semantic search.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Loaded embedding model: all-MiniLM-L6-v2\n",
            "‚úÖ Prepared 24 document chunks for embedding\n",
            "   - From 5 source files\n",
            "   - Types: {'user_story_overview', 'api_endpoint', 'prd_section', 'acceptance_criterion'}\n"
          ]
        }
      ],
      "source": [
        "# Initialize embedding model\n",
        "embedding_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(f\"‚úÖ Loaded embedding model: all-MiniLM-L6-v2\")\n",
        "\n",
        "# Prepare documents for embedding\n",
        "# Split loaded documents into chunks for better retrieval\n",
        "doc_texts = []\n",
        "doc_metadata = []\n",
        "\n",
        "# Process each loaded document\n",
        "for doc in documents:\n",
        "    # Split document into chunks for better retrieval\n",
        "    content = doc['content']\n",
        "    \n",
        "    if doc['type'] == 'text':  # User story\n",
        "        # Split by acceptance criteria\n",
        "        chunks = content.split('Acceptance Criteria:')\n",
        "        \n",
        "        # Add the overview as one chunk\n",
        "        if len(chunks) > 0:\n",
        "            doc_texts.append(chunks[0].strip())\n",
        "            doc_metadata.append({\n",
        "                'type': 'user_story_overview',\n",
        "                'filename': doc['filename'],\n",
        "                'doc_type': doc['metadata']['doc_type'],\n",
        "                'source': doc['metadata']['source']\n",
        "            })\n",
        "        \n",
        "        # Add each acceptance criterion as a separate chunk\n",
        "        if len(chunks) > 1:\n",
        "            criteria = chunks[1].split('\\n\\n')\n",
        "            for i, criterion in enumerate(criteria):\n",
        "                if criterion.strip():\n",
        "                    doc_texts.append(f\"Acceptance Criterion:\\n{criterion.strip()}\")\n",
        "                    doc_metadata.append({\n",
        "                        'type': 'acceptance_criterion',\n",
        "                        'filename': doc['filename'],\n",
        "                        'criterion_index': i + 1,\n",
        "                        'doc_type': doc['metadata']['doc_type'],\n",
        "                        'source': doc['metadata']['source']\n",
        "                    })\n",
        "    \n",
        "    elif doc['type'] == 'markdown':  # PRD\n",
        "        # Split by sections (headers)\n",
        "        sections = content.split('\\n## ')\n",
        "        \n",
        "        for section in sections:\n",
        "            if section.strip():\n",
        "                doc_texts.append(section.strip())\n",
        "                # Extract section title\n",
        "                section_lines = section.strip().split('\\n')\n",
        "                section_title = section_lines[0].replace('#', '').strip() if section_lines else 'Unknown Section'\n",
        "                \n",
        "                doc_metadata.append({\n",
        "                    'type': 'prd_section',\n",
        "                    'filename': doc['filename'],\n",
        "                    'section': section_title,\n",
        "                    'doc_type': doc['metadata']['doc_type'],\n",
        "                    'source': doc['metadata']['source']\n",
        "                })\n",
        "    \n",
        "    elif doc['type'] == 'api_spec':  # API specification\n",
        "        # Split by API endpoints\n",
        "        lines = content.split('\\n')\n",
        "        current_endpoint = []\n",
        "        current_path = None\n",
        "        \n",
        "        for line in lines:\n",
        "            if line.strip().startswith('/api/'):\n",
        "                # Save previous endpoint if exists\n",
        "                if current_endpoint and current_path:\n",
        "                    doc_texts.append('\\n'.join(current_endpoint))\n",
        "                    doc_metadata.append({\n",
        "                        'type': 'api_endpoint',\n",
        "                        'filename': doc['filename'],\n",
        "                        'endpoint': current_path,\n",
        "                        'api_version': doc['metadata']['api_version'],\n",
        "                        'doc_type': doc['metadata']['doc_type'],\n",
        "                        'source': doc['metadata']['source']\n",
        "                    })\n",
        "                # Start new endpoint\n",
        "                current_path = line.strip().rstrip(':')\n",
        "                current_endpoint = [line]\n",
        "            elif current_endpoint:\n",
        "                current_endpoint.append(line)\n",
        "        \n",
        "        # Save last endpoint\n",
        "        if current_endpoint and current_path:\n",
        "            doc_texts.append('\\n'.join(current_endpoint))\n",
        "            doc_metadata.append({\n",
        "                'type': 'api_endpoint',\n",
        "                'filename': doc['filename'],\n",
        "                'endpoint': current_path,\n",
        "                'api_version': doc['metadata']['api_version'],\n",
        "                'doc_type': doc['metadata']['doc_type'],\n",
        "                'source': doc['metadata']['source']\n",
        "            })\n",
        "\n",
        "# Rename to 'documents' for compatibility with rest of notebook\n",
        "documents = doc_texts\n",
        "\n",
        "print(f\"‚úÖ Prepared {len(documents)} document chunks for embedding\")\n",
        "print(f\"   - From {len(set(m['filename'] for m in doc_metadata))} source files\")\n",
        "print(f\"   - Types: {set(m['type'] for m in doc_metadata)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating embeddings...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd142755118e41f597626dd11c7e2112",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Generated embeddings with shape: (24, 384)\n",
            "‚úÖ Created FAISS index with 24 vectors\n",
            "   Dimension: 384\n",
            "\n",
            "üîç Test Query: 'How to test patient data security and HIPAA compliance?'\n",
            "\n",
            "üìö Retrieved Documents:\n",
            "\n",
            "1. Type: prd_section\n",
            "   Score: 0.585\n",
            "   Title: N/A\n",
            "   Preview: 2. Test Objectives\n",
            "\n",
            "- Verify all user management features work as specified in requirements\n",
            "- Ensure HIPAA compliance for all user data handling\n",
            "- Val...\n",
            "\n",
            "2. Type: prd_section\n",
            "   Score: 0.509\n",
            "   Title: N/A\n",
            "   Preview: 3. Test Strategy\n",
            "\n",
            "### 3.1 Functional Testing\n",
            "- **Positive Testing**: Verify all features work with valid inputs\n",
            "- **Negative Testing**: Validate error...\n",
            "\n",
            "3. Type: prd_section\n",
            "   Score: 0.467\n",
            "   Title: N/A\n",
            "   Preview: 5. Test Data Requirements\n",
            "\n",
            "- Valid test email addresses\n",
            "- Test user accounts with different roles\n",
            "- Sample PHI data (anonymized)\n",
            "- Performance testing...\n"
          ]
        }
      ],
      "source": [
        "# Generate embeddings\n",
        "print(\"Generating embeddings...\")\n",
        "embeddings = embedding_model.encode(documents, show_progress_bar=True)\n",
        "embeddings = embeddings.astype('float32')\n",
        "\n",
        "print(f\"‚úÖ Generated embeddings with shape: {embeddings.shape}\")\n",
        "\n",
        "# Create FAISS index\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings)\n",
        "\n",
        "print(f\"‚úÖ Created FAISS index with {index.ntotal} vectors\")\n",
        "print(f\"   Dimension: {dimension}\")\n",
        "\n",
        "# Create a retrieval function\n",
        "def retrieve_context(query: str, k: int = 5) -> List[Tuple[str, Dict, float]]:\n",
        "    \"\"\"\n",
        "    Retrieve relevant documents for a query\n",
        "    \n",
        "    Args:\n",
        "        query: Search query\n",
        "        k: Number of documents to retrieve\n",
        "    \n",
        "    Returns:\n",
        "        List of (document, metadata, similarity_score) tuples\n",
        "    \"\"\"\n",
        "    # Generate query embedding\n",
        "    query_embedding = embedding_model.encode([query]).astype('float32')\n",
        "    \n",
        "    # Search index\n",
        "    distances, indices = index.search(query_embedding, k)\n",
        "    \n",
        "    # Prepare results\n",
        "    results = []\n",
        "    for dist, idx in zip(distances[0], indices[0]):\n",
        "        if idx < len(documents):\n",
        "            similarity = 1 / (1 + dist)  # Convert distance to similarity\n",
        "            results.append((documents[idx], doc_metadata[idx], similarity))\n",
        "    \n",
        "    return results\n",
        "\n",
        "# Test retrieval\n",
        "test_query = \"How to test patient data security and HIPAA compliance?\"\n",
        "print(f\"\\nüîç Test Query: '{test_query}'\")\n",
        "results = retrieve_context(test_query, k=3)\n",
        "\n",
        "print(\"\\nüìö Retrieved Documents:\")\n",
        "for i, (doc, meta, score) in enumerate(results, 1):\n",
        "    print(f\"\\n{i}. Type: {meta.get('type', 'unknown')}\")\n",
        "    print(f\"   Score: {score:.3f}\")\n",
        "    print(f\"   Title: {meta.get('title', meta.get('pattern', meta.get('standard', 'N/A')))}\")\n",
        "    print(f\"   Preview: {doc[:150]}...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Build RAG Pipeline with Gemini\n",
        "\n",
        "Implement the complete RAG pipeline that retrieves relevant context and uses Gemini to generate test cases.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ RAG Test Case Generator initialized\n"
          ]
        }
      ],
      "source": [
        "class RAGTestCaseGenerator:\n",
        "    \"\"\"\n",
        "    Retrieval-Augmented Generation pipeline for test case generation\n",
        "    using FAISS for retrieval and Gemini for generation\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, index, documents, metadata, embedding_model, gemini_model):\n",
        "        self.index = index\n",
        "        self.documents = documents\n",
        "        self.metadata = metadata\n",
        "        self.embedding_model = embedding_model\n",
        "        self.gemini_model = gemini_model\n",
        "        \n",
        "    def retrieve(self, query: str, k: int = 5) -> List[Tuple[str, Dict, float]]:\n",
        "        \"\"\"Retrieve relevant documents\"\"\"\n",
        "        query_embedding = self.embedding_model.encode([query]).astype('float32')\n",
        "        distances, indices = self.index.search(query_embedding, k)\n",
        "        \n",
        "        results = []\n",
        "        for dist, idx in zip(distances[0], indices[0]):\n",
        "            if idx < len(self.documents):\n",
        "                similarity = 1 / (1 + dist)\n",
        "                results.append((self.documents[idx], self.metadata[idx], similarity))\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def generate_test_case(self, requirement: str, num_context: int = 5) -> Dict:\n",
        "        \"\"\"\n",
        "        Generate a test case using RAG\n",
        "        \n",
        "        Args:\n",
        "            requirement: The requirement to generate a test case for\n",
        "            num_context: Number of context documents to retrieve\n",
        "        \n",
        "        Returns:\n",
        "            Generated test case as a dictionary\n",
        "        \"\"\"\n",
        "        # Step 1: Retrieve relevant context\n",
        "        context_docs = self.retrieve(requirement, k=num_context)\n",
        "        \n",
        "        # Step 2: Build context string\n",
        "        context_str = self._build_context_string(context_docs)\n",
        "        \n",
        "        # Step 3: Create prompt with retrieved context\n",
        "        prompt = self._create_generation_prompt(requirement, context_str)\n",
        "        \n",
        "        # Step 4: Generate with Gemini\n",
        "        try:\n",
        "            # Create a simpler prompt without forcing JSON mime type\n",
        "            structured_prompt = f\"\"\"You are a software testing expert. Generate a detailed test case for the following requirement:\n",
        "\n",
        "{requirement}\n",
        "\n",
        "CONTEXT FROM DOCUMENTS:\n",
        "{context_str[:800]}\n",
        "\n",
        "Create a test case with ALL of these fields (be specific and detailed):\n",
        "- id: Unique ID like TC_XXX\n",
        "- title: Clear descriptive title\n",
        "- description: What exactly is being tested\n",
        "- category: (Functional/Security/Integration/Performance)\n",
        "- priority: (High/Medium/Low)\n",
        "- compliance: List relevant standards like HIPAA, GDPR\n",
        "- preconditions: What must be true before testing\n",
        "- test_steps: Detailed numbered steps (at least 3-5 steps)\n",
        "- expected_results: Specific expected outcomes\n",
        "- test_data: Sample data needed for testing\n",
        "- edge_cases: Special scenarios to consider\n",
        "\n",
        "Format your response as a valid JSON object starting with {{ and ending with }}.\n",
        "Example format:\n",
        "{{\n",
        "  \"id\": \"TC_001\",\n",
        "  \"title\": \"Verify user login with valid credentials\",\n",
        "  \"description\": \"Test that users can successfully log in\",\n",
        "  \"category\": \"Functional\",\n",
        "  \"priority\": \"High\",\n",
        "  \"compliance\": [\"HIPAA\"],\n",
        "  \"preconditions\": \"User account exists\",\n",
        "  \"test_steps\": [\"Navigate to login\", \"Enter credentials\", \"Click submit\"],\n",
        "  \"expected_results\": \"User is logged in successfully\",\n",
        "  \"test_data\": \"username: test@example.com, password: Test123!\",\n",
        "  \"edge_cases\": [\"Session timeout\", \"Multiple login attempts\"]\n",
        "}}\"\"\"\n",
        "\n",
        "            # Generate without forcing JSON mime type\n",
        "            response = self.gemini_model.generate_content(\n",
        "                structured_prompt,\n",
        "                generation_config={\n",
        "                    'temperature': 0.3,  # Slightly higher for creativity\n",
        "                    'top_p': 0.9,\n",
        "                    'top_k': 30,\n",
        "                    'max_output_tokens': 1500,\n",
        "                },\n",
        "                safety_settings=safety_settings\n",
        "            )\n",
        "            \n",
        "            # Extract text safely\n",
        "            raw_text = None\n",
        "            if hasattr(response, 'text'):\n",
        "                try:\n",
        "                    raw_text = response.text\n",
        "                except Exception:\n",
        "                    pass\n",
        "            \n",
        "            if not raw_text and hasattr(response, 'candidates') and response.candidates:\n",
        "                try:\n",
        "                    if response.candidates[0].content.parts:\n",
        "                        raw_text = response.candidates[0].content.parts[0].text\n",
        "                except Exception:\n",
        "                    pass\n",
        "            \n",
        "            if not raw_text:\n",
        "                raise ValueError(\"No response text available\")\n",
        "            \n",
        "            # Clean and parse JSON\n",
        "            test_case = None\n",
        "            \n",
        "            # Remove common problematic patterns\n",
        "            cleaned = raw_text.strip()\n",
        "            cleaned = cleaned.replace('```json', '').replace('```', '')\n",
        "            cleaned = cleaned.replace('\\n\\n', '\\n')\n",
        "            \n",
        "            # Try direct JSON parse\n",
        "            try:\n",
        "                test_case = json.loads(cleaned)\n",
        "            except json.JSONDecodeError:\n",
        "                # Try to extract JSON object\n",
        "                import re\n",
        "                # More robust JSON extraction\n",
        "                patterns = [\n",
        "                    r'\\{[^{}]*(?:\\{[^{}]*\\}[^{}]*)*\\}',  # Nested objects\n",
        "                    r'\\{[^\\}]+\\}',  # Simple object\n",
        "                    r'\\{.*\\}',  # Greedy match\n",
        "                ]\n",
        "                \n",
        "                for pattern in patterns:\n",
        "                    matches = re.findall(pattern, cleaned, re.DOTALL)\n",
        "                    for match in matches:\n",
        "                        try:\n",
        "                            # Try to fix common issues\n",
        "                            fixed = match\n",
        "                            # Fix trailing commas\n",
        "                            fixed = re.sub(r',\\s*}', '}', fixed)\n",
        "                            fixed = re.sub(r',\\s*]', ']', fixed)\n",
        "                            # Try parse\n",
        "                            test_case = json.loads(fixed)\n",
        "                            if isinstance(test_case, dict) and 'id' in test_case:\n",
        "                                break\n",
        "                        except:\n",
        "                            continue\n",
        "                    if test_case:\n",
        "                        break\n",
        "            \n",
        "            # Validate and enhance test case\n",
        "            if test_case and isinstance(test_case, dict):\n",
        "                # Ensure required fields\n",
        "                if 'id' not in test_case:\n",
        "                    test_case['id'] = f'TC_{datetime.now().strftime(\"%H%M%S\")}'\n",
        "                if 'title' not in test_case:\n",
        "                    test_case['title'] = requirement[:50]\n",
        "                if 'test_steps' not in test_case or not test_case['test_steps']:\n",
        "                    test_case['test_steps'] = [\"Setup test environment\", \"Execute test\", \"Verify results\"]\n",
        "                if 'compliance' not in test_case:\n",
        "                    test_case['compliance'] = ['HIPAA']\n",
        "                    \n",
        "                # Add metadata\n",
        "                test_case['generated_from'] = requirement\n",
        "                test_case['context_used'] = [meta.get('filename', 'Unknown') \n",
        "                                            for _, meta, _ in context_docs[:3]]\n",
        "                return test_case\n",
        "            else:\n",
        "                raise ValueError(\"Could not generate valid test case\")\n",
        "                \n",
        "        except Exception as e:\n",
        "            # Don't print every error in batch mode\n",
        "            if len(requirement) < 100:  # Likely not batch mode\n",
        "                print(f\"‚ö†Ô∏è Using fallback: {str(e)[:50]}...\")\n",
        "            return self._create_fallback_test_case(requirement)\n",
        "    \n",
        "    def _build_context_string(self, context_docs: List) -> str:\n",
        "        \"\"\"Build formatted context string from retrieved documents\"\"\"\n",
        "        context_parts = []\n",
        "        \n",
        "        for doc, meta, score in context_docs[:3]:  # Use top 3 most relevant\n",
        "            doc_type = meta.get('type', 'unknown')\n",
        "            if doc_type == 'test_case':\n",
        "                context_parts.append(f\"Similar Test Case:\\n{doc}\\n\")\n",
        "            elif doc_type == 'requirement':\n",
        "                context_parts.append(f\"Related Requirement:\\n{doc}\\n\")\n",
        "            elif doc_type == 'compliance':\n",
        "                context_parts.append(f\"Compliance Standard:\\n{doc}\\n\")\n",
        "            elif doc_type == 'test_pattern':\n",
        "                context_parts.append(f\"Test Pattern:\\n{doc}\\n\")\n",
        "        \n",
        "        return \"\\n---\\n\".join(context_parts)\n",
        "    \n",
        "    def _create_generation_prompt(self, requirement: str, context: str) -> str:\n",
        "        \"\"\"Create the prompt for Gemini\"\"\"\n",
        "        prompt = f\"\"\"You are a healthcare software testing expert. Generate a comprehensive test case based on the following requirement and context.\n",
        "\n",
        "REQUIREMENT:\n",
        "{requirement}\n",
        "\n",
        "RELEVANT CONTEXT:\n",
        "{context}\n",
        "\n",
        "Generate a detailed test case that includes:\n",
        "1. Test Case ID (format: TC_XXXX)\n",
        "2. Title (clear and descriptive)\n",
        "3. Description (what is being tested)\n",
        "4. Category (e.g., Security, Clinical, Integration, etc.)\n",
        "5. Priority (Critical/High/Medium/Low)\n",
        "6. Compliance Standards (e.g., HIPAA, GDPR, FDA)\n",
        "7. Preconditions (what must be true before testing)\n",
        "8. Test Steps (numbered, detailed steps)\n",
        "9. Expected Results (specific outcomes)\n",
        "10. Test Data Requirements\n",
        "11. Edge Cases to Consider\n",
        "\n",
        "Format the response as a structured JSON object.\n",
        "\n",
        "Focus on:\n",
        "- Healthcare-specific requirements\n",
        "- Patient safety considerations\n",
        "- Data privacy and security\n",
        "- Regulatory compliance\n",
        "- Clinical accuracy\n",
        "\"\"\"\n",
        "        return prompt\n",
        "    \n",
        "    def _parse_response(self, response_text: str) -> Dict:\n",
        "        \"\"\"Parse Gemini response into structured test case\"\"\"\n",
        "        import re\n",
        "        \n",
        "        # Try to extract JSON from response\n",
        "        try:\n",
        "            # Look for JSON in the response\n",
        "            json_match = re.search(r'\\{.*\\}', response_text, re.DOTALL)\n",
        "            if json_match:\n",
        "                return json.loads(json_match.group())\n",
        "        except:\n",
        "            pass\n",
        "        \n",
        "        # Fallback: Parse text response\n",
        "        test_case = {\n",
        "            'id': self._extract_field(response_text, 'ID', 'TC_AUTO'),\n",
        "            'title': self._extract_field(response_text, 'Title', 'Generated Test Case'),\n",
        "            'description': self._extract_field(response_text, 'Description', response_text[:200]),\n",
        "            'category': self._extract_field(response_text, 'Category', 'General'),\n",
        "            'priority': self._extract_field(response_text, 'Priority', 'Medium'),\n",
        "            'compliance': self._extract_list(response_text, 'Compliance'),\n",
        "            'preconditions': self._extract_field(response_text, 'Preconditions', 'System is operational'),\n",
        "            'test_steps': self._extract_list(response_text, 'Steps'),\n",
        "            'expected_results': self._extract_field(response_text, 'Expected', 'System functions as specified'),\n",
        "            'test_data': self._extract_field(response_text, 'Test Data', 'Standard test data'),\n",
        "            'edge_cases': self._extract_list(response_text, 'Edge Cases')\n",
        "        }\n",
        "        \n",
        "        return test_case\n",
        "    \n",
        "    def _extract_field(self, text: str, field: str, default: str) -> str:\n",
        "        \"\"\"Extract a field value from text\"\"\"\n",
        "        import re\n",
        "        pattern = rf'{field}[:\\s]+([^\\n]+)'\n",
        "        match = re.search(pattern, text, re.IGNORECASE)\n",
        "        return match.group(1).strip() if match else default\n",
        "    \n",
        "    def _extract_list(self, text: str, field: str) -> List[str]:\n",
        "        \"\"\"Extract a list from text\"\"\"\n",
        "        import re\n",
        "        # Find the section\n",
        "        pattern = rf'{field}[:\\s]*\\n((?:[-‚Ä¢\\d]+[.\\s]+[^\\n]+\\n?)+)'\n",
        "        match = re.search(pattern, text, re.IGNORECASE | re.MULTILINE)\n",
        "        \n",
        "        if match:\n",
        "            items_text = match.group(1)\n",
        "            # Extract individual items\n",
        "            items = re.findall(r'[-‚Ä¢\\d]+[.\\s]+([^\\n]+)', items_text)\n",
        "            return [item.strip() for item in items]\n",
        "        \n",
        "        return []\n",
        "    \n",
        "    def _create_fallback_test_case(self, requirement: str) -> Dict:\n",
        "        \"\"\"Create a basic test case when generation fails\"\"\"\n",
        "        return {\n",
        "            'id': f'TC_{datetime.now().strftime(\"%H%M%S\")}',\n",
        "            'title': f'Test: {requirement[:50]}',\n",
        "            'description': f'Verify that {requirement}',\n",
        "            'category': 'General',\n",
        "            'priority': 'Medium',\n",
        "            'compliance': ['HIPAA'],\n",
        "            'preconditions': 'System is in stable state',\n",
        "            'test_steps': [\n",
        "                'Navigate to relevant module',\n",
        "                'Perform required action',\n",
        "                'Verify outcome'\n",
        "            ],\n",
        "            'expected_results': 'System behaves as specified',\n",
        "            'test_data': 'Standard test data',\n",
        "            'edge_cases': [],\n",
        "            'generated_from': requirement,\n",
        "            'context_used': [],\n",
        "            'fallback': True\n",
        "        }\n",
        "    \n",
        "    def batch_generate(self, requirements: List[str], progress: bool = True) -> List[Dict]:\n",
        "        \"\"\"Generate test cases for multiple requirements\"\"\"\n",
        "        test_cases = []\n",
        "        \n",
        "        iterator = tqdm(requirements) if progress else requirements\n",
        "        \n",
        "        for req in iterator:\n",
        "            if progress:\n",
        "                iterator.set_description(f\"Generating: {req[:30]}...\")\n",
        "            \n",
        "            test_case = self.generate_test_case(req)\n",
        "            test_cases.append(test_case)\n",
        "        \n",
        "        return test_cases\n",
        "    \n",
        "    def evaluate_generation(self, test_case: Dict) -> Dict:\n",
        "        \"\"\"Evaluate the quality of a generated test case\"\"\"\n",
        "        evaluation = {\n",
        "            'completeness': 0,\n",
        "            'compliance_coverage': 0,\n",
        "            'detail_level': 0,\n",
        "            'healthcare_specificity': 0,\n",
        "            'overall_score': 0\n",
        "        }\n",
        "        \n",
        "        # Check completeness\n",
        "        required_fields = ['id', 'title', 'description', 'test_steps', 'expected_results']\n",
        "        completeness = sum(1 for field in required_fields if test_case.get(field)) / len(required_fields)\n",
        "        evaluation['completeness'] = completeness\n",
        "        \n",
        "        # Check compliance coverage\n",
        "        if test_case.get('compliance'):\n",
        "            evaluation['compliance_coverage'] = min(len(test_case['compliance']) / 3, 1.0)\n",
        "        \n",
        "        # Check detail level\n",
        "        if test_case.get('test_steps'):\n",
        "            evaluation['detail_level'] = min(len(test_case['test_steps']) / 5, 1.0)\n",
        "        \n",
        "        # Check healthcare specificity\n",
        "        healthcare_keywords = ['patient', 'clinical', 'HIPAA', 'medical', 'healthcare', \n",
        "                              'diagnosis', 'treatment', 'PHI', 'provider']\n",
        "        text = str(test_case).lower()\n",
        "        keyword_count = sum(1 for keyword in healthcare_keywords if keyword in text)\n",
        "        evaluation['healthcare_specificity'] = min(keyword_count / 3, 1.0)\n",
        "        \n",
        "        # Calculate overall score\n",
        "        evaluation['overall_score'] = sum(evaluation.values()) / 4\n",
        "        \n",
        "        return evaluation\n",
        "\n",
        "# Initialize RAG pipeline\n",
        "rag_generator = RAGTestCaseGenerator(\n",
        "    index=index,\n",
        "    documents=documents,\n",
        "    metadata=doc_metadata,\n",
        "    embedding_model=embedding_model,\n",
        "    gemini_model=model\n",
        ")\n",
        "\n",
        "print(\"‚úÖ RAG Test Case Generator initialized\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Generate Test Cases Using RAG\n",
        "\n",
        "Now let's demonstrate the RAG pipeline by generating test cases for various requirements from our loaded documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Requirement: Test user registration with valid email and password according to acceptance criteria\n",
            "\n",
            "üîç Retrieving relevant context...\n",
            "Found 3 relevant documents\n",
            "\n",
            "üìÑ Document 1:\n",
            "   Type: acceptance_criterion\n",
            "   Source: user_story_registration.txt\n",
            "   Relevance: 66.56%\n",
            "   Preview: Acceptance Criterion:\n",
            "1. **Successful Registration:** Given a user is on the registration page, when...\n",
            "\n",
            "üìÑ Document 2:\n",
            "   Type: prd_section\n",
            "   Source: test_plan_user_management.md\n",
            "   Relevance: 58.19%\n",
            "   Preview: 4. Test Scenarios\n",
            "\n",
            "### Registration Testing\n",
            "1. **Valid Registration Flow**\n",
            "   - Test with valid emai...\n",
            "\n",
            "üìÑ Document 3:\n",
            "   Type: acceptance_criterion\n",
            "   Source: user_story_registration.txt\n",
            "   Relevance: 57.10%\n",
            "   Preview: Acceptance Criterion:\n",
            "4. **Password Mismatch Error:** Given a user is on the registration page, when...\n",
            "\n",
            "‚ö° Generating test case with Gemini...\n",
            "\n",
            "‚úÖ Generated Test Case:\n",
            "==================================================\n",
            "EMAIL: valid.newuser@example.com\n",
            "PASSWORD: StrongP@ssw0rd123!\n",
            "CONFIRM_PASSWORD: StrongP@ssw0rd123!\n",
            "ID: TC_185318\n",
            "TITLE: Test user registration with valid email and passwo\n",
            "TEST_STEPS:\n",
            "  - Setup test environment\n",
            "  - Execute test\n",
            "  - Verify results\n",
            "COMPLIANCE:\n",
            "  - HIPAA\n",
            "GENERATED_FROM: Test user registration with valid email and password according to acceptance criteria\n",
            "CONTEXT_USED:\n",
            "  - user_story_registration.txt\n",
            "  - test_plan_user_management.md\n",
            "  - user_story_registration.txt\n",
            "\n",
            "üìä Quality Evaluation:\n",
            "   completeness: 60.00%\n",
            "   compliance_coverage: 33.33%\n",
            "   detail_level: 60.00%\n",
            "   healthcare_specificity: 0.00%\n",
            "   overall_score: 38.33%\n"
          ]
        }
      ],
      "source": [
        "# Example 1: Generate test case for user registration\n",
        "requirement_1 = \"Test user registration with valid email and password according to acceptance criteria\"\n",
        "\n",
        "print(\"üéØ Requirement:\", requirement_1)\n",
        "print(\"\\nüîç Retrieving relevant context...\")\n",
        "\n",
        "# Retrieve context\n",
        "context_docs = rag_generator.retrieve(requirement_1, k=3)\n",
        "print(f\"Found {len(context_docs)} relevant documents\")\n",
        "\n",
        "for i, (doc, meta, score) in enumerate(context_docs, 1):\n",
        "    print(f\"\\nüìÑ Document {i}:\")\n",
        "    print(f\"   Type: {meta.get('type')}\")\n",
        "    print(f\"   Source: {meta.get('filename', 'Unknown')}\")\n",
        "    print(f\"   Relevance: {score:.2%}\")\n",
        "    print(f\"   Preview: {doc[:100]}...\")\n",
        "\n",
        "print(\"\\n‚ö° Generating test case with Gemini...\")\n",
        "test_case_1 = rag_generator.generate_test_case(requirement_1)\n",
        "\n",
        "# Display generated test case\n",
        "print(\"\\n‚úÖ Generated Test Case:\")\n",
        "print(\"=\" * 50)\n",
        "for key, value in test_case_1.items():\n",
        "    if isinstance(value, list):\n",
        "        print(f\"{key.upper()}:\")\n",
        "        for item in value:\n",
        "            print(f\"  - {item}\")\n",
        "    else:\n",
        "        print(f\"{key.upper()}: {value}\")\n",
        "\n",
        "# Evaluate the test case\n",
        "evaluation = rag_generator.evaluate_generation(test_case_1)\n",
        "print(\"\\nüìä Quality Evaluation:\")\n",
        "for metric, score in evaluation.items():\n",
        "    print(f\"   {metric}: {score:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üéØ Requirement: Test the /api/v1/users/register endpoint with invalid email format\n",
            "‚ö†Ô∏è Using fallback: Could not generate valid test case...\n",
            "\n",
            "‚úÖ Generated API Test Case:\n",
            "ID: TC_185326\n",
            "Title: Test: Test the /api/v1/users/register endpoint with inva\n",
            "Category: General\n",
            "Priority: Medium\n",
            "\n",
            "Test Steps:\n",
            "  1. Navigate to relevant module\n",
            "  2. Perform required action\n",
            "  3. Verify outcome\n",
            "\n",
            "Expected Result: System behaves as specified\n"
          ]
        }
      ],
      "source": [
        "# Example 2: Generate API test case\n",
        "requirement_2 = \"Test the /api/v1/users/register endpoint with invalid email format\"\n",
        "\n",
        "print(\"üéØ Requirement:\", requirement_2)\n",
        "test_case_2 = rag_generator.generate_test_case(requirement_2)\n",
        "\n",
        "print(\"\\n‚úÖ Generated API Test Case:\")\n",
        "print(f\"ID: {test_case_2.get('id')}\")\n",
        "print(f\"Title: {test_case_2.get('title')}\")\n",
        "print(f\"Category: {test_case_2.get('category')}\")\n",
        "print(f\"Priority: {test_case_2.get('priority')}\")\n",
        "\n",
        "if test_case_2.get('test_steps'):\n",
        "    print(\"\\nTest Steps:\")\n",
        "    for i, step in enumerate(test_case_2.get('test_steps', []), 1):\n",
        "        print(f\"  {i}. {step}\")\n",
        "\n",
        "print(f\"\\nExpected Result: {test_case_2.get('expected_results')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Batch Test Case Generation\n",
        "\n",
        "Generate multiple test cases based on different requirements extracted from our documents.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üöÄ Generating 8 test cases...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating: Verify HIPAA compliance for pa...:  25%|‚ñà‚ñà‚ñå       | 2/8 [00:17<00:53,  8.94s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Using fallback: Could not generate valid test case...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating: Test API authentication with i...:  38%|‚ñà‚ñà‚ñà‚ñä      | 3/8 [00:27<00:47,  9.46s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Using fallback: Could not generate valid test case...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating: Validate password strength req...:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 4/8 [00:38<00:39,  9.96s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Using fallback: Could not generate valid test case...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating: Test user profile data encrypt...:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [00:46<00:27,  9.25s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚ö†Ô∏è Using fallback: Could not generate valid test case...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Generating: Test user profile data encrypt...:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 5/8 [00:48<00:29,  9.69s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33müöÄ Generating \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(test_requirements)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m test cases...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Generate test cases in batch\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m generated_test_cases = \u001b[43mrag_generator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch_generate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_requirements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m‚úÖ Successfully generated \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(generated_test_cases)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m test cases!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Analyze the generated test cases\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 317\u001b[39m, in \u001b[36mRAGTestCaseGenerator.batch_generate\u001b[39m\u001b[34m(self, requirements, progress)\u001b[39m\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m progress:\n\u001b[32m    315\u001b[39m         iterator.set_description(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerating: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreq[:\u001b[32m30\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     test_case = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_test_case\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m     test_cases.append(test_case)\n\u001b[32m    320\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m test_cases\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 87\u001b[39m, in \u001b[36mRAGTestCaseGenerator.generate_test_case\u001b[39m\u001b[34m(self, requirement, num_context)\u001b[39m\n\u001b[32m     50\u001b[39m             structured_prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\u001b[33mYou are a software testing expert. Generate a detailed test case for the following requirement:\u001b[39m\n\u001b[32m     51\u001b[39m \n\u001b[32m     52\u001b[39m \u001b[38;5;132;01m{\u001b[39;00mrequirement\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     83\u001b[39m \u001b[33m  \u001b[39m\u001b[33m\"\u001b[39m\u001b[33medge_cases\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m: [\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSession timeout\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMultiple login attempts\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m]\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;130;01m}}\u001b[39;00m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m     86\u001b[39m             \u001b[38;5;66;03m# Generate without forcing JSON mime type\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m             response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgemini_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstructured_prompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     89\u001b[39m \u001b[43m                \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Slightly higher for creativity\u001b[39;49;00m\n\u001b[32m     91\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m                    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmax_output_tokens\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m                \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m                \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[43m=\u001b[49m\u001b[43msafety_settings\u001b[49m\n\u001b[32m     96\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     98\u001b[39m             \u001b[38;5;66;03m# Extract text safely\u001b[39;00m\n\u001b[32m     99\u001b[39m             raw_text = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/generativeai/generative_models.py:331\u001b[39m, in \u001b[36mGenerativeModel.generate_content\u001b[39m\u001b[34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[39m\n\u001b[32m    329\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_iterator(iterator)\n\u001b[32m    330\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types.GenerateContentResponse.from_response(response)\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.InvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:835\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    834\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m835\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    843\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/api_core/gapic_v1/method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/api_core/retry/retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/api_core/timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/api_core/grpc_helpers.py:76\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(callable_)\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34merror_remapped_callable\u001b[39m(*args, **kwargs):\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/grpc/_interceptor.py:277\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.__call__\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\n\u001b[32m    269\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    270\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m    275\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    276\u001b[39m ) -> Any:\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     response, ignored_call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_with_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/grpc/_interceptor.py:329\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m    326\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[32m    327\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m _FailureOutcome(exception, sys.exc_info()[\u001b[32m2\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m329\u001b[39m call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_interceptor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintercept_unary_unary\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontinuation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m call.result(), call\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/grpc.py:79\u001b[39m, in \u001b[36m_LoggingClientInterceptor.intercept_unary_unary\u001b[39m\u001b[34m(self, continuation, client_call_details, request)\u001b[39m\n\u001b[32m     64\u001b[39m     grpc_request = {\n\u001b[32m     65\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mpayload\u001b[39m\u001b[33m\"\u001b[39m: request_payload,\n\u001b[32m     66\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mrequestMethod\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mgrpc\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     67\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mdict\u001b[39m(request_metadata),\n\u001b[32m     68\u001b[39m     }\n\u001b[32m     69\u001b[39m     _LOGGER.debug(\n\u001b[32m     70\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSending request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclient_call_details.method\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     71\u001b[39m         extra={\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m         },\n\u001b[32m     77\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m response = \u001b[43mcontinuation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclient_call_details\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m logging_enabled:  \u001b[38;5;66;03m# pragma: NO COVER\u001b[39;00m\n\u001b[32m     81\u001b[39m     response_metadata = response.trailing_metadata()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/grpc/_interceptor.py:315\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._with_call.<locals>.continuation\u001b[39m\u001b[34m(new_details, request)\u001b[39m\n\u001b[32m    306\u001b[39m (\n\u001b[32m    307\u001b[39m     new_method,\n\u001b[32m    308\u001b[39m     new_timeout,\n\u001b[32m   (...)\u001b[39m\u001b[32m    312\u001b[39m     new_compression,\n\u001b[32m    313\u001b[39m ) = _unwrap_client_call_details(new_details, client_call_details)\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     response, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_thunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_method\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_credentials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_wait_for_ready\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_compression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    323\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _UnaryOutcome(response, call)\n\u001b[32m    324\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m rpc_error:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/grpc/_channel.py:1189\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable.with_call\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwith_call\u001b[39m(\n\u001b[32m   1181\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1182\u001b[39m     request: Any,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1187\u001b[39m     compression: Optional[grpc.Compression] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1188\u001b[39m ) -> Tuple[Any, grpc.Call]:\n\u001b[32m-> \u001b[39m\u001b[32m1189\u001b[39m     state, call = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[32m   1191\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1192\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Personal/GenAI Hack /venv/lib/python3.13/site-packages/grpc/_channel.py:1162\u001b[39m, in \u001b[36m_UnaryUnaryMultiCallable._blocking\u001b[39m\u001b[34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[39m\n\u001b[32m   1145\u001b[39m state.target = _common.decode(\u001b[38;5;28mself\u001b[39m._target)\n\u001b[32m   1146\u001b[39m call = \u001b[38;5;28mself\u001b[39m._channel.segregated_call(\n\u001b[32m   1147\u001b[39m     cygrpc.PropagationConstants.GRPC_PROPAGATE_DEFAULTS,\n\u001b[32m   1148\u001b[39m     \u001b[38;5;28mself\u001b[39m._method,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1160\u001b[39m     \u001b[38;5;28mself\u001b[39m._registered_call_handle,\n\u001b[32m   1161\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1162\u001b[39m event = \u001b[43mcall\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1163\u001b[39m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m._response_deserializer)\n\u001b[32m   1164\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
            "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[39m, in \u001b[36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next_call_event\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:97\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:80\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._internal_latent_event\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[39m, in \u001b[36mgrpc._cython.cygrpc._next\u001b[39m\u001b[34m()\u001b[39m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Define test requirements based on our loaded documents\n",
        "test_requirements = [\n",
        "    \"Test successful user registration with all required fields\",\n",
        "    \"Test password reset token expiration after 24 hours\",\n",
        "    \"Verify HIPAA compliance for patient data handling\",\n",
        "    \"Test API authentication with invalid credentials\",\n",
        "    \"Validate password strength requirements\",\n",
        "    \"Test user profile data encryption at rest\",\n",
        "    \"Verify audit trail generation for PHI access\",\n",
        "    \"Test concurrent user registration handling\"\n",
        "]\n",
        "\n",
        "print(f\"üöÄ Generating {len(test_requirements)} test cases...\\n\")\n",
        "\n",
        "# Generate test cases in batch\n",
        "generated_test_cases = rag_generator.batch_generate(test_requirements, progress=True)\n",
        "\n",
        "print(f\"\\n‚úÖ Successfully generated {len(generated_test_cases)} test cases!\")\n",
        "\n",
        "# Analyze the generated test cases\n",
        "categories = {}\n",
        "priorities = {}\n",
        "compliance_standards = set()\n",
        "\n",
        "for tc in generated_test_cases:\n",
        "    # Count categories\n",
        "    category = tc.get('category', 'Unknown')\n",
        "    categories[category] = categories.get(category, 0) + 1\n",
        "    \n",
        "    # Count priorities\n",
        "    priority = tc.get('priority', 'Unknown')\n",
        "    priorities[priority] = priorities.get(priority, 0) + 1\n",
        "    \n",
        "    # Collect compliance standards\n",
        "    if tc.get('compliance'):\n",
        "        compliance_standards.update(tc['compliance'])\n",
        "\n",
        "print(\"\\nüìä Test Case Analysis:\")\n",
        "print(f\"Categories: {categories}\")\n",
        "print(f\"Priorities: {priorities}\")\n",
        "print(f\"Compliance Standards Covered: {list(compliance_standards)}\")\n",
        "\n",
        "# Calculate average quality score\n",
        "avg_scores = {'completeness': 0, 'compliance_coverage': 0, 'detail_level': 0, 'healthcare_specificity': 0}\n",
        "for tc in generated_test_cases:\n",
        "    eval_scores = rag_generator.evaluate_generation(tc)\n",
        "    for key in avg_scores:\n",
        "        avg_scores[key] += eval_scores[key]\n",
        "\n",
        "for key in avg_scores:\n",
        "    avg_scores[key] /= len(generated_test_cases)\n",
        "\n",
        "print(\"\\nüìà Average Quality Metrics:\")\n",
        "for metric, score in avg_scores.items():\n",
        "    print(f\"   {metric}: {score:.2%}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Export Generated Test Cases\n",
        "\n",
        "Save the generated test cases for use in test management tools.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Export test cases to different formats\n",
        "\n",
        "# 1. Export as JSON\n",
        "output_dir = \"/Users/shtlpmac036/Documents/Personal/GenAI Hack /data/generated_test_cases\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Save as JSON\n",
        "json_file = os.path.join(output_dir, f\"test_cases_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\")\n",
        "with open(json_file, 'w') as f:\n",
        "    json.dump(generated_test_cases, f, indent=2)\n",
        "print(f\"‚úÖ Saved {len(generated_test_cases)} test cases to: {json_file}\")\n",
        "\n",
        "# 2. Export as CSV for test management tools\n",
        "df = pd.DataFrame(generated_test_cases)\n",
        "\n",
        "# Flatten lists for CSV export\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col] = df[col].apply(lambda x: '; '.join(x) if isinstance(x, list) else x)\n",
        "\n",
        "csv_file = os.path.join(output_dir, f\"test_cases_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\")\n",
        "df.to_csv(csv_file, index=False)\n",
        "print(f\"‚úÖ Exported test cases to CSV: {csv_file}\")\n",
        "\n",
        "# 3. Create a formatted test document\n",
        "doc_file = os.path.join(output_dir, f\"test_document_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md\")\n",
        "with open(doc_file, 'w') as f:\n",
        "    f.write(\"# Generated Test Cases\\n\\n\")\n",
        "    f.write(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
        "    f.write(f\"Total Test Cases: {len(generated_test_cases)}\\n\\n\")\n",
        "    \n",
        "    for tc in generated_test_cases:\n",
        "        f.write(f\"## {tc.get('id', 'TC_XXX')}: {tc.get('title', 'Untitled')}\\n\\n\")\n",
        "        f.write(f\"**Category:** {tc.get('category', 'N/A')}\\\\n\")\n",
        "        f.write(f\"**Priority:** {tc.get('priority', 'N/A')}\\\\n\")\n",
        "        f.write(f\"**Compliance:** {', '.join(tc.get('compliance', [])) or 'N/A'}\\\\n\\\\n\")\n",
        "        \n",
        "        f.write(f\"### Description\\\\n{tc.get('description', 'N/A')}\\\\n\\\\n\")\n",
        "        \n",
        "        f.write(\"### Test Steps\\\\n\")\n",
        "        for i, step in enumerate(tc.get('test_steps', []), 1):\n",
        "            f.write(f\"{i}. {step}\\\\n\")\n",
        "        \n",
        "        f.write(f\"\\\\n### Expected Results\\\\n{tc.get('expected_results', 'N/A')}\\\\n\\\\n\")\n",
        "        f.write(\"---\\\\n\\\\n\")\n",
        "\n",
        "print(f\"‚úÖ Created formatted test document: {doc_file}\")\n",
        "\n",
        "# Display sample of exported data\n",
        "print(\"\\nüìã Sample Test Case (First Entry):\")\n",
        "print(json.dumps(generated_test_cases[0], indent=2)[:500] + \"...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéÆ Interactive Test Case Generation\n",
        "\n",
        "Try generating your own test cases by modifying the requirement below!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive test case generation\n",
        "# Modify the requirement below and run the cell to generate a custom test case\n",
        "\n",
        "# üéØ MODIFY THIS REQUIREMENT\n",
        "custom_requirement = \"\"\"\n",
        "Test the password complexity validation to ensure it meets the following criteria:\n",
        "- Minimum 8 characters\n",
        "- At least one uppercase letter\n",
        "- At least one number\n",
        "- At least one special character\n",
        "\"\"\"\n",
        "\n",
        "print(\"üéØ Custom Requirement:\")\n",
        "print(custom_requirement)\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Generate test case\n",
        "print(\"\\n‚ö° Generating custom test case...\")\n",
        "custom_test_case = rag_generator.generate_test_case(custom_requirement)\n",
        "\n",
        "# Display the generated test case in a formatted way\n",
        "print(\"\\n‚úÖ Generated Test Case:\\n\")\n",
        "print(f\"üìå ID: {custom_test_case.get('id')}\")\n",
        "print(f\"üìù Title: {custom_test_case.get('title')}\")\n",
        "print(f\"üìÅ Category: {custom_test_case.get('category')}\")\n",
        "print(f\"‚ö†Ô∏è  Priority: {custom_test_case.get('priority')}\")\n",
        "print(f\"üè• Compliance: {', '.join(custom_test_case.get('compliance', []))}\")\n",
        "\n",
        "print(\"\\nüìã Test Steps:\")\n",
        "for i, step in enumerate(custom_test_case.get('test_steps', []), 1):\n",
        "    print(f\"   {i}. {step}\")\n",
        "\n",
        "print(f\"\\n‚úì Expected Result: {custom_test_case.get('expected_results')}\")\n",
        "\n",
        "# Quality check\n",
        "quality = rag_generator.evaluate_generation(custom_test_case)\n",
        "print(f\"\\nüìä Quality Score: {quality['overall_score']:.2%}\")\n",
        "\n",
        "# Tip for users\n",
        "print(\"\\nüí° TIP: Modify the 'custom_requirement' variable above with your own test requirement and re-run this cell!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
